{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the imports used in the program\n",
    "\n",
    "import pandas as pd \n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "from keras.layers import GlobalMaxPool1D, Conv1D, Dropout, GRU, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab data from a database\n",
    "\n",
    "def getData(Server, Database, query):    \n",
    "    \n",
    "    #create a SQL connection based on the given server and database\n",
    "    sql_conn = pyodbc.connect('DRIVER={SQL Server};'\n",
    "                          'SERVER='+Server+';' \n",
    "                          'DATABASE='+Database+';' \n",
    "                          'Trusted_Connection=yes')\n",
    "    \n",
    "    #return the data from the given Query and SQL connection,\n",
    "    #here i hard coded the index so all queries must select examCode\n",
    "    #for other instances just simply change or remove depending on use\n",
    "    return pd.read_sql(query, sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish my server and corresponding database to pull data from\n",
    "server ='GESTALT-BT41Q'\n",
    "database = 'MClinical'\n",
    "\n",
    "#this query grabs sectionValues with their corresponding examCode and description\n",
    "#does not select examCodes if there is less than 100 section values for the corresponding examCode\n",
    "#Stores the result in a pandas DataFrame object called data\n",
    "query = \"SELECT CPTCODEKEY.CPT88304, CPTCODEKEY.CPT88305, CPTCODEKEY.CPT88307, CPTCODEKEY.CPT88309, CPTCODEKEY.CPT88331, CPTCODEKEY.CPT88341, CPTCODEKEY.CPT88342, CPTCODEKEY.CPT88112, CPTCODEKEY.CPT88141, CPTCODEKEY.CPT88175, description, CONCAT(ResultSection.sectionValue, TEMP.VAL) AS sectionValue FROM (SELECT ResultSection.sectionValue AS VAL, Patient.patientKey AS KEYY FROM [MClinical].[dbo].[Result] LEFT JOIN ResultSection ON Result.resultKey = ResultSection.resultKey left join mapResultRequestedProcedure ON Result.resultKey = mapResultRequestedProcedure.resultKey left join RequestedProcedure ON mapResultRequestedProcedure.requestedProcedureKey = RequestedProcedure.requestedProcedureKey left join FillerOrder ON RequestedProcedure.fillerOrderKey = FillerOrder.fillerOrderKey left join PlacerOrder ON FillerOrder.placerOrderKey = PlacerOrder.placerOrderKey left join ExamCode ON PlacerOrder.examCodeKey = ExamCode.examCodeKey left join Patient on FillerOrder.patientKey = Patient.patientKey left join cptcodekey on patient.patientkey = cptcodekey.patient_key WHERE sectionValue <> ' ' and (ResultSection.sectionValue <>' No diagnosis; performed technical only ') and ResultSection.sectionCategory like '%PATHOL%' and description is not null and Patient.patientKey in ( select patient_key from cptcodekey )) AS TEMP LEFT JOIN Patient ON TEMP.KEYY = Patient.patientKey LEFT JOIN CPTCODEKEY ON Patient.patientKey = cptcodekey.patient_key LEFT JOIN FillerOrder ON  CPTCODEKEY.patient_key = FillerOrder.patientKey LEFT JOIN PlacerOrder ON FillerOrder.placerOrderKey = PlacerOrder.placerOrderKey LEFT JOIN ExamCode ON PlacerOrder.examCodeKey = ExamCode.examCodeKey LEFT JOIN RequestedProcedure ON FillerOrder.fillerOrderKey = RequestedProcedure.fillerOrderKey LEFT JOIN mapResultRequestedProcedure ON RequestedProcedure.requestedProcedureKey = mapResultRequestedProcedure.requestedProcedureKey LEFT JOIN ResultSection ON mapResultRequestedProcedure.resultKey = ResultSection.resultKey WHERE sectionValue <> ' ' and (ResultSection.sectionValue <>' No diagnosis; performed technical only ') and ResultSection.sectionCategory like '%gross%' and description is not null and Patient.patientKey in ( select patient_key from cptcodekey ) order by patient.patientkey\"\n",
    "\n",
    "\n",
    "original = getData(server,database,query)\n",
    "data = original.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.sectionValue.values:\n",
    "    if(type(i) == float):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes words that have at one colon somewhere in the middle of two words\n",
    "#and words that have two colons separated by three words. \n",
    "\n",
    "def removeColon(df):\n",
    "    \n",
    "    #Word array of words that i will later remove\n",
    "    bagOfWords = []\n",
    "    \n",
    "    #a array of every word in the sectionValue on the given dataframe df\n",
    "    wordList = df.sectionValue.str.split(expand=True).stack()\n",
    "    \n",
    "    for word in wordList:\n",
    "        colonWord = re.search(r\"\\w+:\\w+:\\w+\", word)\n",
    "        if colonWord is None:\n",
    "            colonWord = re.search(r\"\\w+:\\w+\", word)\n",
    "        if colonWord is not None:\n",
    "            if colonWord.group() not in bagOfWords:\n",
    "                bagOfWords.append(colonWord.group())\n",
    "    \n",
    "    #return the updated dataframe sectionValue, only keeping words that are not contained in bagOfWords            \n",
    "    return df['sectionValue'].apply(lambda x: ' '.join([word for word in x.split() if word not in (bagOfWords)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is more useful than it looks.\n",
    "\n",
    "You pass in a pandas DataFrame and tweak it.\n",
    "\n",
    "First, i create a empty list called bagOfWords\n",
    "\n",
    "The next line seemes confusing but bassically what I am doing here is taking every word from the sectionValue column and creating a list in which each row only contains one word. This helps with the iterative process. I store the result of this into WordList(approx 1.4 million words)\n",
    "\n",
    "Next, i iterate through every word in the wordList in a for loop.\n",
    "\n",
    "let me explain how the search process works and what words i am looking to add to my bagOfWords\n",
    "1. How does the search processWork?\n",
    "    1. I use Regex(regular expression) to do my searching for me which is on a character by character basis\n",
    "2. What kind of words am i looking for?\n",
    "    1. \\w+:\\w+ and \\w+:\\w+:\\w+\n",
    "        1. \\w searches for any character in the form [a-zA-Z0-9]\n",
    "        2. \\+ searches for the previous search condition until the end of the word. \n",
    "        3. : specifies that i want a colon \n",
    "        4. putting it all together \n",
    "            1. \\w+:\\w+ searches for a character in the form [a-zA-Z0-9] for any amount of characters in that form until it hits a colon : in which then it does the same \\w+ until the end of the word.\n",
    "            2. \\w+:\\w+:\\w+ is the same as above just has two colons i hope you get the picture..\n",
    "            \n",
    "     \n",
    "Since i am searching for two different types of words i need to search two different times for every word in wordList.\n",
    "\n",
    "I search the word to see if it matches the pattern of having three words separated by 2 colons, this returns a match object which i store in colonWord.\n",
    "\n",
    "if the word isnt found in the search it returns None, so i check if colonWord is None. If it is i search for the different type of word and store that searches result into colonWord.\n",
    "\n",
    "After that process is done i finally check to see if either of my searches came back true(not None)\n",
    "\n",
    "If they do i use colonWord.group() function to grab just the string(word) that it found.\n",
    "\n",
    "Then Check the bagOfWords to see if the word i found is already in it. \n",
    "\n",
    "If the word is already in it I move onto the next word in the wordList.\n",
    "\n",
    "if it is not, i simply  add it and move to the next word as well. \n",
    "\n",
    "Finally once i have scanned all words and created my bagOfWords that is a unique list i remove those words from the sectionValue column of the Data. \n",
    "\n",
    "what the last line in the funtion is doing is recreating my column sectionValue, but only keeping words that are NOT in bagOfWords.\n",
    "\n",
    "Once that is done i return the new column of sectionValue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i wanted to remove punctuation from the column sectionValue in my pandas dataFrame\n",
    "#i replace every character that matches with one of the following below with nothing.\n",
    "\n",
    "def removePunctuation(df1):\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace(',', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('.', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('?', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('/', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('/', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('+', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('-', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('=', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('_', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace(')', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('(', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('*', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('&', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('^', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('%', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('$', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('#', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('@', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('!', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('>', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('<', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('[', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace(']', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('{', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('}', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('|', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace(':', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace(';', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('\\'', '')\n",
    "    df1['sectionValue'] = df1['sectionValue'].str.replace('\\\"', '')\n",
    "    return df1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(df):\n",
    "    \n",
    "    #stopWords are words that have relatively no meaning to any actual data\n",
    "    #we dont want that here so lets remove them\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    # add custom stopWords \n",
    "    stop = addStopWords(stop)\n",
    "    \n",
    "    # add this if you want to remove words that are smaller than size two\n",
    "    # change the size to whatever you like \n",
    "    \n",
    "    #df['sectionValue'] = df['sectionValue'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 2]))\n",
    "    \n",
    "    #returning the new sectionValue to the Datafram with words that are not in the StopWords\n",
    "    return df['sectionValue'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding my own custom stopWords\n",
    "#super simple to add as you can see \n",
    "#modify as needed!\n",
    "\n",
    "def addStopWords(stop):\n",
    "    stop.append('-')\n",
    "    stop.append('a')\n",
    "    stop.append('b')\n",
    "    stop.append('c')\n",
    "    stop.append('d')\n",
    "    stop.append('e')\n",
    "    stop.append('f')\n",
    "    stop.append('g')\n",
    "    stop.append('h')\n",
    "    stop.append('i')\n",
    "    stop.append('j')\n",
    "    stop.append('k')\n",
    "    stop.append('l')\n",
    "    stop.append('m')\n",
    "    stop.append('n')\n",
    "    stop.append('o')\n",
    "    stop.append('p')\n",
    "    stop.append('q')\n",
    "    stop.append('r')\n",
    "    stop.append('s')\n",
    "    stop.append('t')\n",
    "    stop.append('u')\n",
    "    stop.append('v')\n",
    "    stop.append('w')\n",
    "    stop.append('x')\n",
    "    stop.append('y')\n",
    "    stop.append('z')\n",
    "    stop.append('no')\n",
    "    stop.append('see')\n",
    "    stop.append('two')\n",
    "    stop.append('0')\n",
    "    stop.append('1')\n",
    "    stop.append('2')\n",
    "    stop.append('3')\n",
    "    stop.append('4')\n",
    "    stop.append('5')\n",
    "    stop.append('6')\n",
    "    stop.append('7')\n",
    "    stop.append('8')\n",
    "    stop.append('9')\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\csorensen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#clean_text transforms words like tomatoes, tomato, tomatos, all to tomato. this is very helpful.\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinate the sectionValue and description feild\n",
    "def concatExamDesc(df):\n",
    "    return  df['description'] + ' ' + df['sectionValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    #change the case of all the words to lower case so there is no case sensitivity.\n",
    "    df['sectionValue'] = df['sectionValue'].str.lower()\n",
    "\n",
    "    #call the removeColon function to remove words with a colon or mulitple colons in the middle of the word\n",
    "    df['sectionValue'] = removeColon(df)\n",
    "\n",
    "    #call the removePuncuation code, notice how i did this after the removeColon function.\n",
    "    #it is important that we call this after the removeColon Function because this would remove colons\n",
    "    #from words we want to remove, and then the remove colon function would never find anything because there is no colons. \n",
    "    df = removePunctuation(df)\n",
    "\n",
    "    #call the removeStopWords function to remove words that have no meaning.\n",
    "    df['sectionValue'] = removeStopWords(df)\n",
    "\n",
    "    #call the clean_text to place words of simularity with the base word (ex: biopsies -> biopsy)\n",
    "    df['sectionValue'] = df.sectionValue.apply(lambda x: clean_text(x))\n",
    "\n",
    "    #add the description to the sectionValue\n",
    "    df['sectionValue'] = concatExamDesc(df)\n",
    "    return df['sectionValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.5164509660955"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sectionValue'] = clean(data)\n",
    "data.sectionValue.apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(df, maxlen, max_words):\n",
    "    #split df into two series\n",
    "    #texts being the sectionValue\n",
    "    #labels being the cooresponding examCode\n",
    "    texts = df.sectionValue\n",
    "    \n",
    "    #convert the series into numpy arrays\n",
    "    texts = texts.values\n",
    "    \n",
    "    #create a tokenizer based on the max_words\n",
    "    #fit the tokenizer to our specific texts\n",
    "    #change our texts to a vetorized integer\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    \n",
    "    #pad sequences ensures that all our vectors are of the same length\n",
    "    x = pad_sequences(sequences, maxlen=maxlen)\n",
    "    \n",
    "    d = defaultdict(LabelEncoder)\n",
    "    \n",
    "    fit = df[['CPT88304', 'CPT88305', 'CPT88307',\n",
    "            'CPT88309', 'CPT88331', 'CPT88341', \n",
    "            'CPT88342', 'CPT88112', 'CPT88141', \n",
    "            'CPT88175']].apply(lambda y: d[y.name].fit_transform(y))   \n",
    "    labels = fit.values\n",
    "\n",
    "    print('Shape of data tensor:', x.shape)\n",
    "    print('Shape of label tensor:', labels.shape)\n",
    "    \n",
    "    #return x, labels, and the last 7000 of x and labels for testing\n",
    "    return x[:17555], labels[:17555], x[-4389:], labels[-4389:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21653 unique tokens.\n",
      "Shape of data tensor: (21944, 190)\n",
      "Shape of label tensor: (21944, 10)\n",
      "(17555, 190)\n",
      "(17555, 10)\n",
      "(4389, 190)\n",
      "(4389, 10)\n"
     ]
    }
   ],
   "source": [
    "#define maxlen as the maximum words to take from each sectionValue\n",
    "#define max_words as the total number of unique words to tokenize\n",
    "\n",
    "maxlen = 190\n",
    "max_words = 22000\n",
    "\n",
    "#create data that can be ran through our model\n",
    "x_train, y_train, x_test, y_test = convert_text(data, maxlen, max_words)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a machine learning model with the following\n",
    "def create_model(max_words,maxlen):\n",
    "    #keras default model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #add an embedding layer with the input dim and input length to what we have already\n",
    "    #configured for our vectorized forms of our text\n",
    "    \n",
    "    #135 BEST THIS FAR .1443 LOSS\n",
    "    #JUST A EMMBEDING LAYER, AND A GLOBAL MAX POOLING\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ADD DROPOUT .15 THEN CONV1D .1393 LOSS EPOCH 3\n",
    "    model.add(Embedding(max_words,135, input_length=maxlen, embeddings_initializer=\"uniform\"))\n",
    "    \n",
    "    #model.add(Bidirectional(LSTM(64)))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(maxlen, 3, padding='valid', activation='relu', strides=1))\n",
    "    #model.add(Dropout(0.15))\n",
    "    \n",
    "    #model.add(Conv1D(maxlen, 3, padding='valid', activation='relu', strides=1))\n",
    "    #model.add(Dropout(0.15))\n",
    "    #model.add(Conv1D(maxlen, 3, padding='valid', activation='relu', strides=1))\n",
    "    #model.add(Dropout(0.15))\n",
    "    #model.add(Conv1D(maxlen, 3, padding='valid', activation='relu', strides=1))\n",
    "    #model.add(Bidirectional(LSTM(256)))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    # create a dense output layer with the units = len(labels_dict)\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    #print the summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_49 (Embedding)     (None, 190, 135)          2970000   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 190, 135)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 188, 190)          77140     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_45 (Glo (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                1910      \n",
      "=================================================================\n",
      "Total params: 3,049,050\n",
      "Trainable params: 3,049,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model = create_model(max_words, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "def train_model(model, x_train, y_train, epochs, batchsize, max_words, max_len):\n",
    "    #compile the model\n",
    "    #optimizer -> rmsprop (standard)\n",
    "    #loss -> sparse categorical crossentropy (because we have a large multiclassifcation probelm)\n",
    "    #meteric -> accuracy\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc']) \n",
    "    #save the history from the model\n",
    "    #set the paramiters\n",
    "    #fit the model \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batchsize,\n",
    "                        validation_split=0.2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14044 samples, validate on 3511 samples\n",
      "Epoch 1/25\n",
      "14044/14044 [==============================] - 48s 3ms/step - loss: 0.3015 - acc: 0.8919 - val_loss: 0.1801 - val_acc: 0.9353\n",
      "Epoch 2/25\n",
      "14044/14044 [==============================] - 49s 3ms/step - loss: 0.1662 - acc: 0.9397 - val_loss: 0.1466 - val_acc: 0.9451\n",
      "Epoch 3/25\n",
      "14044/14044 [==============================] - 46s 3ms/step - loss: 0.1317 - acc: 0.9512 - val_loss: 0.1424 - val_acc: 0.9466\n",
      "Epoch 4/25\n",
      "14044/14044 [==============================] - 47s 3ms/step - loss: 0.0970 - acc: 0.9647 - val_loss: 0.1469 - val_acc: 0.9455\n",
      "Epoch 5/25\n",
      "11200/14044 [======================>.......] - ETA: 8s - loss: 0.0690 - acc: 0.9763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-391-c544b100e832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-390-6bc466825ec8>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, epochs, batchsize, max_words, max_len)\u001b[0m\n\u001b[0;32m     15\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                         validation_split=0.2)\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = train_model(model, x_train, y_train, 25, 100, max_words, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the report for the training process\n",
    "def training_report(history):\n",
    "    #get the data from the model history file \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    #set our epochs\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    #plot the accuracy \n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    #plot the loss\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #display the max values we attained\n",
    "    print('Validation Accuracy: ', val_acc[np.argmax(val_acc)] * 100)\n",
    "    print('Training Accuracy: ', acc[np.argmax(acc)] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  94.5314686459987\n",
      "Training Accuracy:  99.4730844249144\n"
     ]
    }
   ],
   "source": [
    "training_report(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on our set aside testing data\n",
    "def test_model(model, x_test):\n",
    "    #gather the models prediction \n",
    "    \n",
    "    #the model displays its prediction as a list of all the cpt codes \n",
    "    #with percents in each category at how confident the model is for \n",
    "    #each cptCode. \n",
    "    \n",
    "    #since we used a binary classifier\n",
    "    #anything above .5 will  be considered true\n",
    "    #and anything below .5 will be considered false\n",
    "    preds = model.predict(x_test)\n",
    "    \n",
    "    #for ever row in the prediction list\n",
    "    #change every column value for the specific row\n",
    "    #where the percent is above or equal to .5 to 1 \n",
    "    #and below .5 to 0\n",
    "    preds[preds>=0.5] = 1\n",
    "    preds[preds<0.5] = 0\n",
    "    \n",
    "    #convert the list to a numpy array\n",
    "    return np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model against our test data and store the predictions in y_pred\n",
    "y_pred = test_model(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the confusion matrix\n",
    "def test_confusion_matrix(y_pred,y_test):\n",
    "    matrix = skm.multilabel_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    #create a label_dict\n",
    "    temp = ['88304', '88305', '88307',\n",
    "                '88309', '88331', '88341', \n",
    "                '88342', '88112', '88141', \n",
    "                '88175']\n",
    "    label_dict = np.asarray(temp)\n",
    "\n",
    "\n",
    "    #print the confusion matrix \n",
    "    #rows are the models predictions\n",
    "    #columns is the test\n",
    "\n",
    "    #since the matrix is of shape 10 x 2 x 2 \n",
    "    #we will go through each 2 x 2 matrix to display\n",
    "    #each cpt codes individual confusion matrix\n",
    "\n",
    "    x = 0\n",
    "    for i in matrix:\n",
    "        #convert matrix to a pandas df to convert\n",
    "        #index and columns to cpt codes\n",
    "        print(x)\n",
    "        dfmatrix = pd.DataFrame(i, columns=[0,label_dict[x]], index=[0,label_dict[x]])\n",
    "        print(dfmatrix, '\\n\\n')\n",
    "        x = x+1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(y_pred, y_test):\n",
    "    print((1 - skm.hamming_loss(y_test, y_pred)) *100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the classification report\n",
    "def test_classification_report(y_pred,y_test):\n",
    "    #cr from index values\n",
    "    print(skm.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "          0  88304\n",
      "0      3869     13\n",
      "88304   108    399 \n",
      "\n",
      "\n",
      "1\n",
      "         0  88305\n",
      "0      887    189\n",
      "88305   91   3222 \n",
      "\n",
      "\n",
      "2\n",
      "          0  88307\n",
      "0      3152    139\n",
      "88307   190    908 \n",
      "\n",
      "\n",
      "3\n",
      "          0  88309\n",
      "0      4216     19\n",
      "88309    81     73 \n",
      "\n",
      "\n",
      "4\n",
      "          0  88331\n",
      "0      4104     20\n",
      "88331    64    201 \n",
      "\n",
      "\n",
      "5\n",
      "          0  88341\n",
      "0      4011     66\n",
      "88341   168    144 \n",
      "\n",
      "\n",
      "6\n",
      "          0  88342\n",
      "0      3418    150\n",
      "88342   129    692 \n",
      "\n",
      "\n",
      "7\n",
      "          0  88112\n",
      "0      4312      7\n",
      "88112    67      3 \n",
      "\n",
      "\n",
      "8\n",
      "          0  88141\n",
      "0      4308     20\n",
      "88141    46     15 \n",
      "\n",
      "\n",
      "9\n",
      "          0  88175\n",
      "0      4314     14\n",
      "88175    51     10 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87       507\n",
      "           1       0.94      0.97      0.96      3313\n",
      "           2       0.87      0.83      0.85      1098\n",
      "           3       0.79      0.47      0.59       154\n",
      "           4       0.91      0.76      0.83       265\n",
      "           5       0.69      0.46      0.55       312\n",
      "           6       0.82      0.84      0.83       821\n",
      "           7       0.30      0.04      0.07        70\n",
      "           8       0.43      0.25      0.31        61\n",
      "           9       0.42      0.16      0.24        61\n",
      "\n",
      "   micro avg       0.90      0.85      0.87      6662\n",
      "   macro avg       0.71      0.56      0.61      6662\n",
      "weighted avg       0.89      0.85      0.86      6662\n",
      " samples avg       0.93      0.92      0.91      6662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the classification report on the predictions\n",
    "test_classification_report(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.28161312371839\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first n rows\n",
    "def drop_first_n_rows(df, n):\n",
    "    return df.iloc[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop frist 13000 rows in data\n",
    "data = drop_first_n_rows(data, 17555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 1's in columns to cooresponding cpt code\n",
    "def convert_to_cpt_code(Y):\n",
    "    #create a label dict\n",
    "    temp = ['88304', '88305', '88307',\n",
    "            '88309', '88331', '88341', \n",
    "            '88342', '88112', '88141', \n",
    "            '88175']\n",
    "    label_dict = np.asarray(temp)\n",
    "    \n",
    "    #create a container for the 1419 x 10 matrix (big storage container)\n",
    "    temp = []\n",
    "    \n",
    "    #access every row in Y\n",
    "    for row in Y:\n",
    "        #create a container for each row (mini storage container lol)\n",
    "        temp1 = []\n",
    "        i = 0\n",
    "        \n",
    "        #grab every column value in the cooresponding row\n",
    "        for index in row:\n",
    "            #if the value is 1 then append into our mini storage container\n",
    "            if (index == 1):\n",
    "                temp1.append(label_dict[i])\n",
    "            #append a 0    \n",
    "            else:\n",
    "                temp1.append('0')\n",
    "            \n",
    "            #increase the label dict tracker\n",
    "            i = i + 1\n",
    "            \n",
    "        #append the mini storage container to the big storage container\n",
    "        #NUMPY ARRAY !!!\n",
    "        temp.append(np.asarray(temp1))\n",
    "    \n",
    "    #numpy array!!!!!!\n",
    "    return np.asarray(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pred\n",
    "pred = convert_to_cpt_code(y_pred)\n",
    "\n",
    "#convert test\n",
    "test = convert_to_cpt_code(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label dict\n",
    "temp = ['88304', '88305', '88307',\n",
    "        '88309', '88331', '88341', \n",
    "        '88342', '88112', '88141', \n",
    "        '88175']\n",
    "label_dict = np.asarray(temp)\n",
    "\n",
    "#convert our n x 10 numpy arrays to a pandas df\n",
    "pdpred = pd.DataFrame(pred, columns=label_dict)\n",
    "pdtest = pd.DataFrame(test, columns=label_dict)\n",
    "\n",
    "#print(pdpred, '\\n\\n', pdtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace a 0 with nan(aka null)\n",
    "def zero_to_nan(df):\n",
    "    df['88304'].replace('0', np.nan, inplace=True)\n",
    "    df['88305'].replace('0', np.nan, inplace=True)\n",
    "    df['88307'].replace('0', np.nan, inplace=True)\n",
    "    df['88309'].replace('0', np.nan, inplace=True)\n",
    "    df['88331'].replace('0', np.nan, inplace=True)\n",
    "    df['88341'].replace('0', np.nan, inplace=True)\n",
    "    df['88342'].replace('0', np.nan, inplace=True)\n",
    "    df['88112'].replace('0', np.nan, inplace=True)\n",
    "    df['88141'].replace('0', np.nan, inplace=True)\n",
    "    df['88175'].replace('0', np.nan, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zeros from df's \n",
    "\n",
    "pdpred = zero_to_nan(pdpred)\n",
    "pdtest = zero_to_nan(pdtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a comma separated list of the guessed exam codes\n",
    "#store each as truth and pred in cooresponding pandas df's\n",
    "pdtest['truth'] = pdtest[['88304', '88305', '88307', '88309', '88331', '88341', '88342', '88112', '88141', '88175']].apply(lambda x: ', '.join(x[x.notnull()]), axis = 1)\n",
    "pdpred['pred'] = pdpred[['88304', '88305', '88307', '88309', '88331', '88341', '88342', '88112', '88141', '88175']].apply(lambda x: ', '.join(x[x.notnull()]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the pred and truth comma separated list to the original dataframe\n",
    "\n",
    "data['pred'] = pdpred['pred'].values\n",
    "data['truth'] = pdtest['truth'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the useless data\n",
    "\n",
    "data = data.drop(['description', 'CPT88304', 'CPT88305', 'CPT88307',\n",
    "                  'CPT88309', 'CPT88331', 'CPT88341', \n",
    "                  'CPT88342', 'CPT88112', 'CPT88141', \n",
    "                  'CPT88175'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************** DO NOT RUN THIS... DEVELOPMENT TESTING ONLY ********************\n",
    "data = data.drop(['truth', 'pred'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex the columns of the data\n",
    "data = data.reindex(columns=['truth', 'pred', 'sectionValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>pred</th>\n",
       "      <th>sectionValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>A. CYST/TAG/DEBRIDMENT receive formalin label ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17556</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>A. CYST/TAG/DEBRIDMENT receive formalin label ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. BREAST NEEDLE BIOPSY, RIGHT specimen label ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17560</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. BREAST NEEDLE BIOPSY, RIGHT specimen label ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17561</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SIGMOID POLYP labeleddesignated johnson sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SIGMOID POLYP labeleddesignated johnson sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17563</th>\n",
       "      <td>88304</td>\n",
       "      <td>88304</td>\n",
       "      <td>A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17564</th>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>A. BREAST BIOPSY, WITHOUT SURGICAL MARGINS, LE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565</th>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>A. BREAST BIOPSY, WITHOUT SURGICAL MARGINS, LE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17566</th>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>A. ULTRASOUND GUIDED BREAST NEEDLE BIOPSY spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17567</th>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>A. ULTRASOUND GUIDED BREAST NEEDLE BIOPSY spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>88307, 88331</td>\n",
       "      <td>88307, 88331</td>\n",
       "      <td>A. BRAIN BIOPSY part specimen receive fresh fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88305, 88307, 88341, 88342</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17570</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. AORTIC VALVE specimen label designate elven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17572</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17574</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17575</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ENDOMETRIAL BIOPSY specimen designate shule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17580</th>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17581</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. BREAST, PARTIAL MASTECTOMY, RIGHT specimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17582</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17583</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17584</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SOFT TISSUE, OTHER THAN TUMOR/MASS/LIPOMA/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21914</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. BREAST, PARTIAL MASTECTOMY, RIGHT specimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21915</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>-SKO1,-SKO1 specimen receive formalin specimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21916</th>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>88304, 88305</td>\n",
       "      <td>A. AORTIC VALVE specimen receive formalin spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21917</th>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>88305, 88307, 88341, 88342</td>\n",
       "      <td>-BRSTR-NBX,-BRSTL-NBX,-BRSTR-NBX,-BRSTR-NBX sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21918</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. URINARY BLADDER CHIPS specimen designate be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21919</th>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>88305, 88341, 88342</td>\n",
       "      <td>A. BREAST NEEDLE BIOPSY, RIGHT specimen design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21920</th>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>88305, 88307, 88341, 88342</td>\n",
       "      <td>A. BREAST NEEDLE BIOPSY, RIGHT specimen design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21921</th>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>88305, 88307, 88341, 88342</td>\n",
       "      <td>SLN-BRST,LYM-BX,SLN-BRST,BRSTR-PSMAS specimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21922</th>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>88305, 88307, 88342</td>\n",
       "      <td>SLN-BRST,LYM-BX,SLN-BRST,BRSTR-PSMAS specimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21923</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. ORAL MUCOSAL BIOPSY specimen designate mcgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21924</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. THYROID, TOTAL specimen label designate mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21925</th>\n",
       "      <td>88304</td>\n",
       "      <td>88304</td>\n",
       "      <td>A. CONJUCTIVAL BIOPSY specimen label designate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. TEMPORAL ARTERY BIOPSY specimen label desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. BREAST NEEDLE BIOPSY, RIGHT specimen receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21928</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21929</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>-COL-P,-COL-P specimen receive formalin specim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21930</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. FALLLOPIAN TUBE, ECTOPIC PREGNANCY, LEFT sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21931</th>\n",
       "      <td>88304</td>\n",
       "      <td>88304</td>\n",
       "      <td>A. GALLBLADDER specimen label designate layne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21932</th>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>88305, 88342</td>\n",
       "      <td>-ANT-BX,-COLBX specimen receive formalin speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21933</th>\n",
       "      <td>88305, 88307, 88331</td>\n",
       "      <td>88305, 88331</td>\n",
       "      <td>-OVL-NON,-OVFTR-NEO case receive part specimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21934</th>\n",
       "      <td>88304</td>\n",
       "      <td>88304</td>\n",
       "      <td>A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21935</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>-RECT-P,-SIG-P,-COL-P,-REC four specimen recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21936</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>-SMB-BX,-COLBX,-SIG-P three specimen receive f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21937</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. JOINT, RESECTION specimen label designate h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21938</th>\n",
       "      <td>88307, 88331, 88341, 88342</td>\n",
       "      <td>88305, 88307, 88331, 88341, 88342</td>\n",
       "      <td>-BRAIN-BX,-BRAIN-BX specimen receive specimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21939</th>\n",
       "      <td>88304, 88307, 88309</td>\n",
       "      <td>88304, 88307, 88309</td>\n",
       "      <td>-SOFT,-LYM-RR,-LYM-RR,-PROS-RES specimen recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21940</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. EYE, RIGHT specimen label designate ouren r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21941</th>\n",
       "      <td>88307</td>\n",
       "      <td>88305, 88307</td>\n",
       "      <td>-BRSTR-PSMAS,-BRSTR-PSMAS specimen receive par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21942</th>\n",
       "      <td>88307</td>\n",
       "      <td>88307</td>\n",
       "      <td>A. SMALL BOWEL, RESECTION OTHER THAN FOR TUMOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>88305</td>\n",
       "      <td>88305</td>\n",
       "      <td>A. TOE, AMPUTATION, NON-TRAUMATIC specimen lab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4389 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            truth                               pred  \\\n",
       "17555         88305, 88341, 88342                       88304, 88305   \n",
       "17556         88305, 88341, 88342                       88304, 88305   \n",
       "17557         88305, 88341, 88342                              88305   \n",
       "17558         88305, 88341, 88342                              88305   \n",
       "17559                       88305                              88305   \n",
       "17560                       88305                              88305   \n",
       "17561                       88305                              88305   \n",
       "17562                       88305                              88305   \n",
       "17563                       88304                              88304   \n",
       "17564                88305, 88307                       88305, 88307   \n",
       "17565                88305, 88307                       88305, 88307   \n",
       "17566                88305, 88307                       88305, 88307   \n",
       "17567                88305, 88307                       88305, 88307   \n",
       "17568                88307, 88331                       88307, 88331   \n",
       "17569         88305, 88341, 88342         88305, 88307, 88341, 88342   \n",
       "17570                       88305                              88305   \n",
       "17571                       88305                       88305, 88307   \n",
       "17572                       88305                              88305   \n",
       "17573                       88305                              88305   \n",
       "17574                       88305                              88305   \n",
       "17575                       88305                              88305   \n",
       "17576                       88305                              88305   \n",
       "17577                       88305                              88305   \n",
       "17578                       88305                              88305   \n",
       "17579                       88305                              88305   \n",
       "17580                88304, 88305                       88304, 88305   \n",
       "17581                       88307                              88307   \n",
       "17582                       88305                              88305   \n",
       "17583                       88305                       88305, 88342   \n",
       "17584                       88305                              88305   \n",
       "...                           ...                                ...   \n",
       "21914                       88307                              88307   \n",
       "21915                       88305                              88305   \n",
       "21916                88304, 88305                       88304, 88305   \n",
       "21917         88305, 88341, 88342         88305, 88307, 88341, 88342   \n",
       "21918                       88307                              88307   \n",
       "21919                88305, 88342                88305, 88341, 88342   \n",
       "21920                88305, 88342         88305, 88307, 88341, 88342   \n",
       "21921                88305, 88342         88305, 88307, 88341, 88342   \n",
       "21922                88305, 88342                88305, 88307, 88342   \n",
       "21923                       88305                              88305   \n",
       "21924                       88307                              88307   \n",
       "21925                       88304                              88304   \n",
       "21926                       88305                              88305   \n",
       "21927                       88305                              88305   \n",
       "21928                       88305                              88305   \n",
       "21929                       88305                              88305   \n",
       "21930                       88305                              88305   \n",
       "21931                       88304                              88304   \n",
       "21932                88305, 88342                       88305, 88342   \n",
       "21933         88305, 88307, 88331                       88305, 88331   \n",
       "21934                       88304                              88304   \n",
       "21935                       88305                              88305   \n",
       "21936                       88305                              88305   \n",
       "21937                       88305                              88305   \n",
       "21938  88307, 88331, 88341, 88342  88305, 88307, 88331, 88341, 88342   \n",
       "21939         88304, 88307, 88309                88304, 88307, 88309   \n",
       "21940                       88307                              88307   \n",
       "21941                       88307                       88305, 88307   \n",
       "21942                       88307                              88307   \n",
       "21943                       88305                              88305   \n",
       "\n",
       "                                            sectionValue  \n",
       "17555  A. CYST/TAG/DEBRIDMENT receive formalin label ...  \n",
       "17556  A. CYST/TAG/DEBRIDMENT receive formalin label ...  \n",
       "17557  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "17558  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "17559  A. BREAST NEEDLE BIOPSY, RIGHT specimen label ...  \n",
       "17560  A. BREAST NEEDLE BIOPSY, RIGHT specimen label ...  \n",
       "17561  A. SIGMOID POLYP labeleddesignated johnson sig...  \n",
       "17562  A. SIGMOID POLYP labeleddesignated johnson sig...  \n",
       "17563  A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...  \n",
       "17564  A. BREAST BIOPSY, WITHOUT SURGICAL MARGINS, LE...  \n",
       "17565  A. BREAST BIOPSY, WITHOUT SURGICAL MARGINS, LE...  \n",
       "17566  A. ULTRASOUND GUIDED BREAST NEEDLE BIOPSY spec...  \n",
       "17567  A. ULTRASOUND GUIDED BREAST NEEDLE BIOPSY spec...  \n",
       "17568  A. BRAIN BIOPSY part specimen receive fresh fr...  \n",
       "17569  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "17570  A. AORTIC VALVE specimen label designate elven...  \n",
       "17571  A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...  \n",
       "17572  A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...  \n",
       "17573  A. UTERUS, TUBES AND OVARIES, OTHER THAN FOR N...  \n",
       "17574  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17575  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17576  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17577  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17578  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17579  A. ENDOMETRIAL BIOPSY specimen designate shule...  \n",
       "17580  A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...  \n",
       "17581  A. BREAST, PARTIAL MASTECTOMY, RIGHT specimen ...  \n",
       "17582  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "17583  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "17584  A. SOFT TISSUE, OTHER THAN TUMOR/MASS/LIPOMA/D...  \n",
       "...                                                  ...  \n",
       "21914  A. BREAST, PARTIAL MASTECTOMY, RIGHT specimen ...  \n",
       "21915  -SKO1,-SKO1 specimen receive formalin specimen...  \n",
       "21916  A. AORTIC VALVE specimen receive formalin spec...  \n",
       "21917  -BRSTR-NBX,-BRSTL-NBX,-BRSTR-NBX,-BRSTR-NBX sp...  \n",
       "21918  A. URINARY BLADDER CHIPS specimen designate be...  \n",
       "21919  A. BREAST NEEDLE BIOPSY, RIGHT specimen design...  \n",
       "21920  A. BREAST NEEDLE BIOPSY, RIGHT specimen design...  \n",
       "21921  SLN-BRST,LYM-BX,SLN-BRST,BRSTR-PSMAS specimen ...  \n",
       "21922  SLN-BRST,LYM-BX,SLN-BRST,BRSTR-PSMAS specimen ...  \n",
       "21923  A. ORAL MUCOSAL BIOPSY specimen designate mcgu...  \n",
       "21924  A. THYROID, TOTAL specimen label designate mal...  \n",
       "21925  A. CONJUCTIVAL BIOPSY specimen label designate...  \n",
       "21926  A. TEMPORAL ARTERY BIOPSY specimen label desig...  \n",
       "21927  A. BREAST NEEDLE BIOPSY, RIGHT specimen receiv...  \n",
       "21928  A. SKIN, OTHER THAN CYST/TAG/DEBRIDEMENT/PLAST...  \n",
       "21929  -COL-P,-COL-P specimen receive formalin specim...  \n",
       "21930  A. FALLLOPIAN TUBE, ECTOPIC PREGNANCY, LEFT sp...  \n",
       "21931  A. GALLBLADDER specimen label designate layne ...  \n",
       "21932  -ANT-BX,-COLBX specimen receive formalin speci...  \n",
       "21933  -OVL-NON,-OVFTR-NEO case receive part specimen...  \n",
       "21934  A. SKIN, CYST/TAG/DEBRIDMENT , 1 BLOCK specime...  \n",
       "21935  -RECT-P,-SIG-P,-COL-P,-REC four specimen recei...  \n",
       "21936  -SMB-BX,-COLBX,-SIG-P three specimen receive f...  \n",
       "21937  A. JOINT, RESECTION specimen label designate h...  \n",
       "21938  -BRAIN-BX,-BRAIN-BX specimen receive specimen ...  \n",
       "21939  -SOFT,-LYM-RR,-LYM-RR,-PROS-RES specimen recei...  \n",
       "21940  A. EYE, RIGHT specimen label designate ouren r...  \n",
       "21941  -BRSTR-PSMAS,-BRSTR-PSMAS specimen receive par...  \n",
       "21942  A. SMALL BOWEL, RESECTION OTHER THAN FOR TUMOR...  \n",
       "21943  A. TOE, AMPUTATION, NON-TRAUMATIC specimen lab...  \n",
       "\n",
       "[4389 rows x 3 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsqlconn(Server, Database):    \n",
    "    \n",
    "    #create a SQL connection based on the given server and database\n",
    "    sql_conn = pyodbc.connect('DRIVER={SQL Server};'\n",
    "                          'SERVER='+Server+';' \n",
    "                          'DATABASE='+Database+';' \n",
    "                          'Trusted_Connection=yes')\n",
    "    \n",
    "    #return the data from the given Query and SQL connection,\n",
    "    #here i hard coded the index so all queries must select examCode\n",
    "    #for other instances just simply change or remove depending on use\n",
    "    return sql_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish server\n",
    "server ='GESTALT-BT41Q'\n",
    "\n",
    "#establish database\n",
    "database = 'CPTCode'\n",
    "\n",
    "#get a connection String\n",
    "connStr = getsqlconn(server,database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the cursor\n",
    "cursor = connStr.cursor()\n",
    "\n",
    "#insert into the database our data \n",
    "for index,row in data.iterrows():\n",
    "    cursor.execute(\"INSERT INTO dbo.mltest([idx],[Pred],[Truth],[Val]) values (?,?, ?,?)\" ,index, row['pred'], row['truth'] , row['sectionValue']) \n",
    "    connStr.commit()\n",
    "cursor.close()\n",
    "connStr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
