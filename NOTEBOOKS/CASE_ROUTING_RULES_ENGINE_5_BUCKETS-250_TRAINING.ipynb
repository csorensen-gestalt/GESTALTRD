{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#all the imports used in the program\n",
    "\n",
    "import pandas as pd \n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "from keras.layers import GlobalMaxPool1D, Conv1D, Dropout, GRU, Flatten, MaxPooling1D\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab data from a database\n",
    "\n",
    "def getData(Server, UID, PWD, Database, query):    \n",
    "    \n",
    "    #create a SQL connection based on the given server and database\n",
    "    sql_conn = pyodbc.connect('DRIVER={SQL Server};'\n",
    "                              'SERVER='+Server+';' \n",
    "                              'UID='+UID+';'\n",
    "                              'PWD='+PWD+';'\n",
    "                              'DATABASE='+Database+';' )\n",
    "    \n",
    "    #return the data from the given Query and SQL connection,\n",
    "    return pd.read_sql(query, sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish my server and corresponding database to pull data from\n",
    "server ='GSDEMO2HOST'\n",
    "database = 'MClinical'\n",
    "UID = 'gsanalytics'\n",
    "PWD = 'G3st@lt'\n",
    "\n",
    "\n",
    "#Stores the result in a pandas DataFrame object called data\n",
    "query =\"SELECT ISNULL(ProcedureStep.subSpecialtyCd,'UNKNOWN') AS subSpecialtyCd, FillerOrder.fillerOrderStatusCd, PL.locationName, BUCKETS.BUCKETNUM FROM BUCKETS LEFT JOIN ProcedureStep ON BUCKETS.PSKEY = ProcedureSteP.procedureStepKey LEFT JOIN RequestedProcedure ON ProcedureStep.requestedProcedureKey = RequestedProcedure.requestedProcedureKey LEFT JOIN FillerOrder ON RequestedProcedure.fillerOrderKey = FillerOrder.fillerOrderKey LEFT JOIN LOCATION AS PL ON FillerOrder.scheduledLocationKey = PL.locationKey\"\n",
    "original = getData(server, UID, PWD, database,query)\n",
    "data = original.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinate the selected params\n",
    "def concatParam(df):\n",
    "    return  df['subSpecialtyCd'] + ' ' + df['fillerOrderStatusCd'] + ' ' + df['locationName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    #create a new column where its all the params concatinated by spaces\n",
    "    df['concat'] = concatParam(df)\n",
    "    \n",
    "    #change the case of all the words to lower case so there is no case sensitivity.\n",
    "    df['concat'] = df['concat'].str.lower()\n",
    "    return df['concat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['concat'] = clean(data)\n",
    "data.concat.apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(df, maxlen, max_words):\n",
    "    #split df into two series\n",
    "    #texts being the concat\n",
    "    #labels being the cooresponding bucket\n",
    "    texts = df.concat\n",
    "    labels = df.BUCKETNUM\n",
    "    \n",
    "    #convert the series into numpy arrays\n",
    "    texts = texts.values\n",
    "    temp_labels = labels.values\n",
    "    \n",
    "    #create a empty array for our labels that we will convert to integers\n",
    "    labels = []\n",
    "    \n",
    "    #grab all the unique buckets (5) \n",
    "    #this will be our dictonary for mapping between integers and buckets\n",
    "    label_dict = [1,2,3,4,5]\n",
    "    label_dict = np.asarray(label_dict)\n",
    "\n",
    "    \n",
    "    for label_type in temp_labels:\n",
    "        labels.append(np.searchsorted(label_dict, label_type))\n",
    "    \n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    #create a tokenizer based on the max_words\n",
    "    #fit the tokenizer to our specific texts\n",
    "    #change our texts to a vetorized integer\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    \n",
    "    #pad sequences ensures that all our vectors are of the same length\n",
    "    x = pad_sequences(sequences, maxlen=maxlen)\n",
    "    \n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    print('Shape of data tensor:', x.shape)\n",
    "    print('Shape of label tensor:', labels.shape)\n",
    "    \n",
    "    #return x, labels, and the last 7000 of x and labels for testing\n",
    "    return x[:1000], labels[:1000], x[-9000:], labels[-9000:], indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 unique tokens.\n",
      "Shape of data tensor: (10000, 8)\n",
      "Shape of label tensor: (10000,)\n",
      "(1000, 8)\n",
      "(1000,)\n",
      "(9000, 8)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "#define maxlen as the maximum words to take from each sectionValue\n",
    "#define max_words as the total number of unique words to tokenize\n",
    "\n",
    "maxlen = 8\n",
    "max_words = 20\n",
    "\n",
    "#create data that can be ran through our model\n",
    "x_train, y_train, x_test, y_test, index = convert_text(data, maxlen, max_words)\n",
    "\n",
    "data = data.reindex(index)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a machine learning model with the following\n",
    "def create_model(max_words,maxlen):\n",
    "    #keras default model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #add an embedding layer with the input dim and input length to what we have already\n",
    "    #configured for our vectorized forms of our text\n",
    "    model.add(Embedding(input_dim = max_words, input_length=maxlen, output_dim = 50))\n",
    "    \n",
    "    #model.add(Embedding(max_words,50, input_length=maxlen, embeddings_initializer=\"uniform\"))\n",
    "    \n",
    "    #add a bidirectional LSTM layer with 32 units\n",
    "    model.add(Bidirectional(LSTM(units =32)))\n",
    "    \n",
    "    #model.add(Conv1D(maxlen, 1, padding='valid', activation='relu', strides=1))\n",
    "    #model.add(GlobalMaxPool1D())\n",
    "    \n",
    "    # create a dense output layer with the units = len(labels_dict)\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    #print the summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\csorensen\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 50)             1000      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                21248     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 22,573\n",
      "Trainable params: 22,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model = create_model(max_words, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "def train_model(model, x_train, y_train, epochs, batchsize, max_words, max_len):\n",
    "    #compile the model\n",
    "    #optimizer -> rmsprop (standard)\n",
    "    #loss -> sparse categorical crossentropy (because we have a large multiclassifcation probelm)\n",
    "    #meteric -> accuracy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc']) \n",
    "    #save the history from the model\n",
    "    #set the paramiters\n",
    "    #fit the model \n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batchsize,\n",
    "                        validation_split=0.75)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\csorensen\\.conda\\envs\\test\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 250 samples, validate on 750 samples\n",
      "Epoch 1/120\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5970 - acc: 0.2920 - val_loss: 1.5749 - val_acc: 0.3107\n",
      "Epoch 2/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 1.5681 - acc: 0.3200 - val_loss: 1.5487 - val_acc: 0.3107\n",
      "Epoch 3/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 1.5408 - acc: 0.3200 - val_loss: 1.5157 - val_acc: 0.3107\n",
      "Epoch 4/120\n",
      "250/250 [==============================] - 0s 270us/step - loss: 1.5070 - acc: 0.3200 - val_loss: 1.4839 - val_acc: 0.3107\n",
      "Epoch 5/120\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.4745 - acc: 0.3200 - val_loss: 1.4481 - val_acc: 0.3107\n",
      "Epoch 6/120\n",
      "250/250 [==============================] - 0s 285us/step - loss: 1.4360 - acc: 0.3200 - val_loss: 1.4089 - val_acc: 0.3107\n",
      "Epoch 7/120\n",
      "250/250 [==============================] - 0s 315us/step - loss: 1.3963 - acc: 0.3200 - val_loss: 1.3658 - val_acc: 0.3107\n",
      "Epoch 8/120\n",
      "250/250 [==============================] - 0s 277us/step - loss: 1.3514 - acc: 0.3200 - val_loss: 1.3118 - val_acc: 0.3107\n",
      "Epoch 9/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 1.2872 - acc: 0.3200 - val_loss: 1.2582 - val_acc: 0.3133\n",
      "Epoch 10/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 1.2232 - acc: 0.3280 - val_loss: 1.1790 - val_acc: 0.3253\n",
      "Epoch 11/120\n",
      "250/250 [==============================] - 0s 275us/step - loss: 1.1401 - acc: 0.4560 - val_loss: 1.0966 - val_acc: 0.5827\n",
      "Epoch 12/120\n",
      "250/250 [==============================] - 0s 244us/step - loss: 1.0494 - acc: 0.6600 - val_loss: 1.0033 - val_acc: 0.7107\n",
      "Epoch 13/120\n",
      "250/250 [==============================] - 0s 273us/step - loss: 0.9518 - acc: 0.7120 - val_loss: 0.9074 - val_acc: 0.7067\n",
      "Epoch 14/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.8537 - acc: 0.7240 - val_loss: 0.8151 - val_acc: 0.7107\n",
      "Epoch 15/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 0.7573 - acc: 0.7320 - val_loss: 0.7222 - val_acc: 0.8800\n",
      "Epoch 16/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.6653 - acc: 0.8840 - val_loss: 0.6439 - val_acc: 0.8800\n",
      "Epoch 17/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 0.5850 - acc: 0.8840 - val_loss: 0.5686 - val_acc: 0.8800\n",
      "Epoch 18/120\n",
      "250/250 [==============================] - 0s 270us/step - loss: 0.5075 - acc: 0.8840 - val_loss: 0.4988 - val_acc: 0.8800\n",
      "Epoch 19/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 0.4385 - acc: 0.8840 - val_loss: 0.4459 - val_acc: 0.8800\n",
      "Epoch 20/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 0.3870 - acc: 0.8840 - val_loss: 0.3975 - val_acc: 0.8800\n",
      "Epoch 21/120\n",
      "250/250 [==============================] - 0s 303us/step - loss: 0.3400 - acc: 0.8840 - val_loss: 0.3519 - val_acc: 0.8800\n",
      "Epoch 22/120\n",
      "250/250 [==============================] - 0s 375us/step - loss: 0.2881 - acc: 0.8840 - val_loss: 0.3272 - val_acc: 0.8800\n",
      "Epoch 23/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 0.2637 - acc: 0.9040 - val_loss: 0.2963 - val_acc: 0.8907\n",
      "Epoch 24/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.2266 - acc: 0.9280 - val_loss: 0.2807 - val_acc: 0.9267\n",
      "Epoch 25/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.2041 - acc: 0.9560 - val_loss: 0.2465 - val_acc: 0.9707\n",
      "Epoch 26/120\n",
      "250/250 [==============================] - 0s 259us/step - loss: 0.1782 - acc: 0.9840 - val_loss: 0.2278 - val_acc: 0.9733\n",
      "Epoch 27/120\n",
      "250/250 [==============================] - 0s 311us/step - loss: 0.1584 - acc: 0.9840 - val_loss: 0.2100 - val_acc: 0.9733\n",
      "Epoch 28/120\n",
      "250/250 [==============================] - 0s 355us/step - loss: 0.1360 - acc: 0.9840 - val_loss: 0.1949 - val_acc: 0.9747\n",
      "Epoch 29/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.1198 - acc: 0.9840 - val_loss: 0.1997 - val_acc: 0.9747\n",
      "Epoch 30/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 0.1095 - acc: 0.9880 - val_loss: 0.1829 - val_acc: 0.9747\n",
      "Epoch 31/120\n",
      "250/250 [==============================] - 0s 254us/step - loss: 0.0970 - acc: 0.9840 - val_loss: 0.1772 - val_acc: 0.9747\n",
      "Epoch 32/120\n",
      "250/250 [==============================] - 0s 259us/step - loss: 0.0871 - acc: 0.9880 - val_loss: 0.1609 - val_acc: 0.9747\n",
      "Epoch 33/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 0.0763 - acc: 0.9880 - val_loss: 0.1895 - val_acc: 0.9773\n",
      "Epoch 34/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0785 - acc: 0.9920 - val_loss: 0.1452 - val_acc: 0.9747\n",
      "Epoch 35/120\n",
      "250/250 [==============================] - 0s 291us/step - loss: 0.0636 - acc: 0.9880 - val_loss: 0.1421 - val_acc: 0.9787\n",
      "Epoch 36/120\n",
      "250/250 [==============================] - 0s 311us/step - loss: 0.0564 - acc: 0.9920 - val_loss: 0.1364 - val_acc: 0.9787\n",
      "Epoch 37/120\n",
      "250/250 [==============================] - 0s 335us/step - loss: 0.0521 - acc: 0.9920 - val_loss: 0.1337 - val_acc: 0.9773\n",
      "Epoch 38/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 0.0453 - acc: 0.9920 - val_loss: 0.1710 - val_acc: 0.9720\n",
      "Epoch 39/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0552 - acc: 0.9920 - val_loss: 0.1260 - val_acc: 0.9787\n",
      "Epoch 40/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0371 - acc: 0.9920 - val_loss: 0.1222 - val_acc: 0.9773\n",
      "Epoch 41/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 0.0312 - acc: 0.9920 - val_loss: 0.1329 - val_acc: 0.9760\n",
      "Epoch 42/120\n",
      "250/250 [==============================] - 0s 255us/step - loss: 0.0317 - acc: 0.9880 - val_loss: 0.1184 - val_acc: 0.9773\n",
      "Epoch 43/120\n",
      "250/250 [==============================] - 0s 287us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9880\n",
      "Epoch 44/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9880\n",
      "Epoch 45/120\n",
      "250/250 [==============================] - 0s 331us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9893\n",
      "Epoch 46/120\n",
      "250/250 [==============================] - 0s 295us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9867\n",
      "Epoch 47/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0200 - acc: 0.9960 - val_loss: 0.1081 - val_acc: 0.9893\n",
      "Epoch 48/120\n",
      "250/250 [==============================] - 0s 299us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9880\n",
      "Epoch 49/120\n",
      "250/250 [==============================] - 0s 287us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9893\n",
      "Epoch 50/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9880\n",
      "Epoch 51/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9893\n",
      "Epoch 52/120\n",
      "250/250 [==============================] - 0s 315us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9840\n",
      "Epoch 53/120\n",
      "250/250 [==============================] - 0s 319us/step - loss: 0.0291 - acc: 0.9960 - val_loss: 0.0984 - val_acc: 0.9880\n",
      "Epoch 54/120\n",
      "250/250 [==============================] - 0s 299us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9880\n",
      "Epoch 55/120\n",
      "250/250 [==============================] - 0s 299us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9893\n",
      "Epoch 56/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9893\n",
      "Epoch 57/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 0.9880\n",
      "Epoch 58/120\n",
      "250/250 [==============================] - 0s 311us/step - loss: 0.0094 - acc: 0.9960 - val_loss: 0.1042 - val_acc: 0.9880\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 327us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9893\n",
      "Epoch 60/120\n",
      "250/250 [==============================] - 0s 287us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9893\n",
      "Epoch 61/120\n",
      "250/250 [==============================] - 0s 255us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9893\n",
      "Epoch 62/120\n",
      "250/250 [==============================] - 0s 263us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9893\n",
      "Epoch 63/120\n",
      "250/250 [==============================] - 0s 286us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9893\n",
      "Epoch 64/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9893\n",
      "Epoch 65/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9893\n",
      "Epoch 66/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9893\n",
      "Epoch 67/120\n",
      "250/250 [==============================] - 0s 278us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9867\n",
      "Epoch 68/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9880\n",
      "Epoch 69/120\n",
      "250/250 [==============================] - 0s 323us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9893\n",
      "Epoch 70/120\n",
      "250/250 [==============================] - 0s 311us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9880\n",
      "Epoch 71/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9893\n",
      "Epoch 72/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9893\n",
      "Epoch 73/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9893\n",
      "Epoch 74/120\n",
      "250/250 [==============================] - 0s 284us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9893\n",
      "Epoch 75/120\n",
      "250/250 [==============================] - 0s 292us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9893\n",
      "Epoch 76/120\n",
      "250/250 [==============================] - 0s 275us/step - loss: 9.5894e-04 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9893\n",
      "Epoch 77/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 8.7699e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9893\n",
      "Epoch 78/120\n",
      "250/250 [==============================] - 0s 319us/step - loss: 8.6712e-04 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9893\n",
      "Epoch 79/120\n",
      "250/250 [==============================] - 0s 327us/step - loss: 7.8954e-04 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9893\n",
      "Epoch 80/120\n",
      "250/250 [==============================] - 0s 327us/step - loss: 6.6434e-04 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9880\n",
      "Epoch 81/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 7.0095e-04 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9893\n",
      "Epoch 82/120\n",
      "250/250 [==============================] - 0s 275us/step - loss: 5.1243e-04 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9893\n",
      "Epoch 83/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 4.5305e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9853\n",
      "Epoch 84/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9893\n",
      "Epoch 85/120\n",
      "250/250 [==============================] - 0s 259us/step - loss: 4.1653e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9893\n",
      "Epoch 86/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 3.5609e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9893\n",
      "Epoch 87/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 3.2536e-04 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9893\n",
      "Epoch 88/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 2.9081e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9893\n",
      "Epoch 89/120\n",
      "250/250 [==============================] - 0s 307us/step - loss: 2.6799e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9893\n",
      "Epoch 90/120\n",
      "250/250 [==============================] - 0s 299us/step - loss: 2.4938e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9893\n",
      "Epoch 91/120\n",
      "250/250 [==============================] - 0s 335us/step - loss: 2.3123e-04 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9893\n",
      "Epoch 92/120\n",
      "250/250 [==============================] - 0s 327us/step - loss: 2.0649e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9893\n",
      "Epoch 93/120\n",
      "250/250 [==============================] - 0s 295us/step - loss: 1.8811e-04 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9893\n",
      "Epoch 94/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 1.6819e-04 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9893\n",
      "Epoch 95/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 1.5081e-04 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9893\n",
      "Epoch 96/120\n",
      "250/250 [==============================] - 0s 291us/step - loss: 1.3516e-04 - acc: 1.0000 - val_loss: 0.1201 - val_acc: 0.9893\n",
      "Epoch 97/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 1.2521e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9893\n",
      "Epoch 98/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 1.0643e-04 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9893\n",
      "Epoch 99/120\n",
      "250/250 [==============================] - 0s 271us/step - loss: 1.0114e-04 - acc: 1.0000 - val_loss: 0.1211 - val_acc: 0.9893\n",
      "Epoch 100/120\n",
      "250/250 [==============================] - 0s 259us/step - loss: 8.1527e-05 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9893\n",
      "Epoch 101/120\n",
      "250/250 [==============================] - 0s 291us/step - loss: 9.4706e-05 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9853\n",
      "Epoch 102/120\n",
      "250/250 [==============================] - 0s 311us/step - loss: 2.8103e-04 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9880\n",
      "Epoch 103/120\n",
      "250/250 [==============================] - 0s 327us/step - loss: 8.8889e-05 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9893\n",
      "Epoch 104/120\n",
      "250/250 [==============================] - 0s 323us/step - loss: 5.6511e-05 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9893\n",
      "Epoch 105/120\n",
      "250/250 [==============================] - 0s 303us/step - loss: 5.0219e-05 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9893\n",
      "Epoch 106/120\n",
      "250/250 [==============================] - 0s 275us/step - loss: 4.5760e-05 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9893\n",
      "Epoch 107/120\n",
      "250/250 [==============================] - 0s 255us/step - loss: 4.1989e-05 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9893\n",
      "Epoch 108/120\n",
      "250/250 [==============================] - 0s 251us/step - loss: 3.8035e-05 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9893\n",
      "Epoch 109/120\n",
      "250/250 [==============================] - 0s 263us/step - loss: 3.4292e-05 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9893\n",
      "Epoch 110/120\n",
      "250/250 [==============================] - 0s 283us/step - loss: 3.2139e-05 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9893\n",
      "Epoch 111/120\n",
      "250/250 [==============================] - 0s 295us/step - loss: 4.9273e-05 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9893\n",
      "Epoch 112/120\n",
      "250/250 [==============================] - 0s 331us/step - loss: 2.6467e-05 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 0.9893\n",
      "Epoch 113/120\n",
      "250/250 [==============================] - 0s 331us/step - loss: 2.3808e-05 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9893\n",
      "Epoch 114/120\n",
      "250/250 [==============================] - 0s 351us/step - loss: 2.2484e-05 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9893\n",
      "Epoch 115/120\n",
      "250/250 [==============================] - 0s 295us/step - loss: 1.9604e-05 - acc: 1.0000 - val_loss: 0.1285 - val_acc: 0.9893\n",
      "Epoch 116/120\n",
      "250/250 [==============================] - 0s 279us/step - loss: 2.4343e-05 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9893\n",
      "Epoch 117/120\n",
      "250/250 [==============================] - 0s 260us/step - loss: 1.6769e-05 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/120\n",
      "250/250 [==============================] - 0s 299us/step - loss: 1.4162e-05 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9893\n",
      "Epoch 119/120\n",
      "250/250 [==============================] - 0s 267us/step - loss: 1.3028e-05 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9893\n",
      "Epoch 120/120\n",
      "250/250 [==============================] - 0s 263us/step - loss: 1.2402e-05 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = train_model(model, x_train, y_train, 120, 80, max_words, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the report for the training process\n",
    "def training_report(history):\n",
    "    #get the data from the model history file \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    #set our epochs\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    #plot the accuracy \n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    \n",
    "    #plot the loss\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #display the max values we attained\n",
    "    print('Validation Accuracy: ', val_acc[np.argmax(val_acc)] * 100)\n",
    "    print('Training Accuracy: ', acc[np.argmax(acc)] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU1dnA8d9DAoSwC9QFkGBdIQSII0ulAmItuKDWDQyuWMRqrcvHVxR3pbVKlWJxr0slBX2pC68brYriUsBEAVFEFgEjKCESFtmS8Lx/nDvJJJlJZpJJZsnz/XzmM3PvPXPvuXOTZ86cexZRVYwxxiS+ZrHOgDHGmOiwgG6MMUnCAroxxiQJC+jGGJMkLKAbY0ySsIBujDFJwgK6CUpEUkRkp4gcGs20sSQih4tI1NvpishJIrIuYHmliPwynLR1ONZTInJLXd9fw37vFZFno71f07hSY50BEx0isjNgMR3YC5R5y1eoam4k+1PVMqBNtNM2Bap6VDT2IyKXA+NUdVjAvi+Pxr5NcrKAniRUtTygeiXAy1X17VDpRSRVVUsbI2/GmMZhVS5NhPeT+gURmSUiO4BxIjJYRBaKSLGIbBKR6SLS3EufKiIqIhne8kxv+5siskNE/isiPSNN620fJSJfi8g2EXlYRD4SkUtC5DucPF4hIqtFZKuITA94b4qIPCQiRSKyBhhZw+dzq4jMrrJuhog86L2+XERWeOezxis9h9pXgYgM816ni8jzXt6+AI4Ncty13n6/EJHR3vo+wN+AX3rVWVsCPts7A94/0Tv3IhF5RUQODuezqY2InOnlp1hE3hWRowK23SIiG0Vku4h8FXCug0TkU2/9DyLyQLjHM1GiqvZIsgewDjipyrp7gX3A6bgv8lbAccBA3C+1w4Cvgau99KmAAhne8kxgC+ADmgMvADPrkPZnwA7gDG/b9UAJcEmIcwknj68C7YEM4Ef/uQNXA18A3YBOwAL3Jx/0OIcBO4HWAfveDPi85dO9NAKcCOwGsrxtJwHrAvZVAAzzXk8F3gM6Aj2AL6ukPQ842LsmF3h5ONDbdjnwXpV8zgTu9F6f7OWxH5AGPAK8G85nE+T87wWe9V4f4+XjRO8a3eJ97s2B3sB64CAvbU/gMO/1J8BY73VbYGCs/xea2sNK6E3Lh6r6f6q6X1V3q+onqrpIVUtVdS3wBDC0hvfPUdU8VS0BcnGBJNK0pwFLVPVVb9tDuOAfVJh5/JOqblPVdbjg6T/WecBDqlqgqkXAfTUcZy2wHPdFA/AroFhV87zt/6eqa9V5F3gHCHrjs4rzgHtVdauqrseVugOP+6KqbvKuyT9xX8a+MPYLkAM8papLVHUPMAkYKiLdAtKE+mxqMgaYq6rvetfoPqAd7ou1FPfl0durtvvG++zAfTEfISKdVHWHqi4K8zxMlFhAb1q+DVwQkaNF5HUR+V5EtgN3A51reP/3Aa93UfON0FBpDwnMh6oqrkQbVJh5DOtYuJJlTf4JjPVeX4D7IvLn4zQRWSQiP4pIMa50XNNn5XdwTXkQkUtEZKlXtVEMHB3mfsGdX/n+VHU7sBXoGpAmkmsWar/7cdeoq6quBG7AXYfNXhXeQV7SS4FewEoRWSwip4R5HiZKLKA3LVWb7D2OK5UerqrtgNtxVQoNaROuCgQAEREqB6Cq6pPHTUD3gOXamlW+AJzklXDPwAV4RKQVMAf4E646pAPw7zDz8X2oPIjIYcCjwJVAJ2+/XwXst7Ymlhtx1Tj+/bXFVe18F0a+ItlvM9w1+w5AVWeq6vG46pYU3OeCqq5U1TG4arW/AP8SkbR65sVEwAJ609YW2Ab8JCLHAFc0wjFfA7JF5HQRSQX+AHRpoDy+CFwrIl1FpBNwU02JVfUH4EPgGWClqq7yNrUEWgCFQJmInAaMiCAPt4hIB3Ht9K8O2NYGF7QLcd9tl+NK6H4/AN38N4GDmAWMF5EsEWmJC6wfqGrIXzwR5Hm0iAzzjn0j7r7HIhE5RkSGe8fb7T3KcCdwoYh09kr027xz21/PvJgIWEBv2m4ALsb9sz6OK6E2KC9ong88CBQBPwc+w7Wbj3YeH8XVdX+Ou2E3J4z3/BN3k/OfAXkuBq4DXsbdWDwH98UUjjtwvxTWAW8C/wjY7zJgOrDYS3M0EFjv/B9gFfCDiARWnfjf/xau6uNl7/2H4urV60VVv8B95o/ivmxGAqO9+vSWwP24+x7f434R3Oq99RRghbhWVFOB81V1X33zY8InrgrTmNgQkRTcT/xzVPWDWOfHmERmJXTT6ERkpIi0936234ZrObE4xtkyJuFZQDexMARYi/vZPhI4U1VDVbkYY8JkVS7GGJMkrIRujDFJImaDc3Xu3FkzMjJidXhjjElI+fn5W1Q1aFPfmAX0jIwM8vLyYnV4Y4xJSCISssezVbkYY0ySsIBujDFJwgK6McYkCZuxyJgmoqSkhIKCAvbs2RPrrJgwpKWl0a1bN5o3DzWUT3UW0I1pIgoKCmjbti0ZGRm4QS5NvFJVioqKKCgooGfPnrW/wVNrlYuIPC0im0VkeQ1phonIEm/KqvfDPnqEcnMhIwOaNXPPuRFNe2xM07Znzx46depkwTwBiAidOnWK+NdUOHXoz1LzXIwdcFNfjVbV3sC5EeUgTLm5MGECrF8Pqu55wgQL6sZEwoJ54qjLtao1oKvqAtyQoaFcALykqhu89JsjzkUYJk+GXbsqr9u1y603xhgTnVYuRwIdReQ9EckXkYtCJRSRCSKSJyJ5hYWFER1kw4bI1htj4ktRURH9+vWjX79+HHTQQXTt2rV8ed++8IZNv/TSS1m5cmWNaWbMmEFulH66DxkyhCVLlkRlX40hGgE9FTgWOBX4NXCbiBwZLKGqPqGqPlX1delS0yQ11R0aYvIwVatPN6YhRPueVadOnViyZAlLlixh4sSJXHfddeXLLVq0ANzNwP37Q09y9Mwzz3DUUUfVeJyrrrqKnJx6z/ORkKIR0AuAt1T1J1XdAiwA+kZhv5VMmQLp6cG3WX26MdHVmPesVq9eTWZmJhMnTiQ7O5tNmzYxYcIEfD4fvXv35u677y5P6y8xl5aW0qFDByZNmkTfvn0ZPHgwmze72t5bb72VadOmlaefNGkSAwYM4KijjuLjjz8G4KeffuLss8+mb9++jB07Fp/PV2tJfObMmfTp04fMzExuueUWAEpLS7nwwgvL10+fPh2Ahx56iF69etG3b1/GjRsX9c8slGgE9FeBX4pIqoikAwOBFVHYbyU5OfDEE3DwwcG3W326MdHT2PesvvzyS8aPH89nn31G165due+++8jLy2Pp0qX85z//4csvv6z2nm3btjF06FCWLl3K4MGDefrpp4PuW1VZvHgxDzzwQPmXw8MPP8xBBx3E0qVLmTRpEp999lmN+SsoKODWW29l/vz5fPbZZ3z00Ue89tpr5Ofns2XLFj7//HOWL1/ORRe5Guf777+fJUuWsHTpUv72t7/V89MJXzjNFmcB/wWOEpECERkvIhNFZCKAqq4A3gKW4WadeUpVQzZxrI+cHNi4MfT29eut+sWYaGjse1Y///nPOe6448qXZ82aRXZ2NtnZ2axYsSJoQG/VqhWjRo0C4Nhjj2XdunVB9/2b3/ymWpoPP/yQMWPGANC3b1969+5dY/4WLVrEiSeeSOfOnWnevDkXXHABCxYs4PDDD2flypX84Q9/YN68ebRv3x6A3r17M27cOHJzcyPqGFRf4bRyGauqB6tqc1Xtpqp/V9XHVPWxgDQPqGovVc1U1WkNm2Xo0SP0Nqt+Mab+Qt2zCrW+vlq3bl3+etWqVfz1r3/l3XffZdmyZYwcOTJoe2x/vTtASkoKpaWlQffdsmXLamkindgnVPpOnTqxbNkyhgwZwvTp07niiisAmDdvHhMnTmTx4sX4fD7KysoiOl5dJeRYLlOmQKtWobdb9Ysx9RPsnlV6ulvf0LZv307btm1p164dmzZtYt68eVE/xpAhQ3jxxRcB+Pzzz4P+Agg0aNAg5s+fT1FREaWlpcyePZuhQ4dSWFiIqnLuuedy11138emnn1JWVkZBQQEnnngiDzzwAIWFheyqWn/VQBKy67//Bvb//E/oKhhrzmhM3fn/xyZPdv9Lhx7qgnljNB7Jzs6mV69eZGZmcthhh3H88cdH/Ri///3vueiii8jKyiI7O5vMzMzy6pJgunXrxt13382wYcNQVU4//XROPfVUPv30U8aPH4+qIiL8+c9/prS0lAsuuIAdO3awf/9+brrpJtq2bRv1cwgmZnOK+nw+jcYEFx07QnFx9fUpKfDcc43zB2hMIlixYgXHHHNMrLMRF0pLSyktLSUtLY1Vq1Zx8skns2rVKlJT46uMG+yaiUi+qvqCpY+v3NfBtGlw6aWuaVWgsjJXlw4W1I0xle3cuZMRI0ZQWlqKqvL444/HXTCvi4Q/g4svhjVr4J57qm/z16VbQDfGBOrQoQP5+fmxzkbUJeRN0aoC+h1UY3XpxpimIikCOkD37sHX29AAxpimImkC+p/+BF5z02qsbboxpilImoCekwN//3vo8V6sbboxJtklTUAHF9RXrQq93erTjYmdYcOGVeskNG3aNH73u9/V+L42bdoAsHHjRs4555yQ+66tGfS0adMqdfA55ZRTKA7W5jlCd955J1OnTq33fqIhqQI6wCGHQIcOwbc1VLdlY0ztxo4dy+zZsyutmz17NmPHjg3r/Ycccghz5syp8/GrBvQ33niDDqGCRYJKuoAO8OCDEGz2pp07rR7dmFg555xzeO2119i7dy8A69atY+PGjQwZMqS8XXh2djZ9+vTh1Vdfrfb+devWkZmZCcDu3bsZM2YMWVlZnH/++ezevbs83ZVXXlk+9O4dd9wBwPTp09m4cSPDhw9n+PDhAGRkZLBlyxYAHnzwQTIzM8nMzCwfenfdunUcc8wx/Pa3v6V3796cfPLJlY4TzJIlSxg0aBBZWVmcddZZbN26tfz4vXr1Iisrq3xQsPfff798go/+/fuzY8eOOn+2fgnfDj2YSy+FpUvhr3+tvL6oyDobGQNw7bUQ7Yl4+vVzHf1C6dSpEwMGDOCtt97ijDPOYPbs2Zx//vmICGlpabz88su0a9eOLVu2MGjQIEaPHh1yXs1HH32U9PR0li1bxrJly8jOzi7fNmXKFA444ADKysoYMWIEy5Yt45prruHBBx9k/vz5dO7cudK+8vPzeeaZZ1i0aBGqysCBAxk6dCgdO3Zk1apVzJo1iyeffJLzzjuPf/3rXzWOb37RRRfx8MMPM3ToUG6//Xbuuusupk2bxn333cc333xDy5Yty6t5pk6dyowZMzj++OPZuXMnaWlpEXzawSVlCR3goYeCt3qxm6PGxE5gtUtgdYuqcsstt5CVlcVJJ53Ed999xw8//BByPwsWLCgPrFlZWWRlZZVve/HFF8nOzqZ///588cUXtQ689eGHH3LWWWfRunVr2rRpw29+8xs++OADAHr27Em/fv2AmofoBTc+e3FxMUOHDgXg4osvZsGCBeV5zMnJYebMmeU9Uo8//niuv/56pk+fTnFxcVR6qiZlCR1clYv3y64auzlqmrqaStIN6cwzz+T666/n008/Zffu3eUl69zcXAoLC8nPz6d58+ZkZGQEHTI3ULDS+zfffMPUqVP55JNP6NixI5dcckmt+6lpPKuWAaXClJSUWqtcQnn99ddZsGABc+fO5Z577uGLL75g0qRJnHrqqbzxxhsMGjSIt99+m6OPPrpO+/cLZ4KLp0Vks4jUOGmFiBwnImUiEvw2dAyEGjfdbo4aExtt2rRh2LBhXHbZZZVuhm7bto2f/exnNG/enPnz57N+/foa93PCCSeUTwS9fPlyli1bBrihd1u3bk379u354YcfePPNN8vf07Zt26D11CeccAKvvPIKu3bt4qeffuLll1/ml7/8ZcTn1r59ezp27Fheun/++ecZOnQo+/fv59tvv2X48OHcf//9FBcXs3PnTtasWUOfPn246aab8Pl8fPXVVxEfs6pwqlyeBUbWlEBEUoA/A9EfuLgepkyBqtVSIjazkTGxNHbsWJYuXVp+cxAgJyeHvLw8fD4fubm5tZZUr7zySnbu3ElWVhb3338/AwYMANzsQ/3796d3795cdtlllYbenTBhAqNGjSq/KeqXnZ3NJZdcwoABAxg4cCCXX345/fv3r9O5Pffcc9x4441kZWWxZMkSbr/9dsrKyhg3bhx9+vShf//+XHfddXTo0IFp06aRmZlJ3759K82+VB9hDZ8rIhnAa6qaGWL7tUAJcJyXrta2RdEaPrc2/slug40vn57u5im1G6SmKbDhcxNPpMPn1vumqIh0Bc4CHqstbSzk5MDixcG32Q1SY0wyiUYrl2nATapa66R5IjJBRPJEJK+wsDAKhw5PTfO/2g1SY0yyiEZA9wGzRWQdcA7wiIicGSyhqj6hqj5V9XXp0iUKhw7fQQcFX283SE1TEqsZykzk6nKt6h3QVbWnqmaoagYwB/idqr5S3/1G29Sp0KzK2TbWpLfGxIO0tDSKioosqCcAVaWoqCjizka1tkMXkVnAMKCziBQAdwDNvYPGZb15MDk5sGJFRQBPSalch243Rk2y69atGwUFBTRmdaepu7S0NLp16xbRexJ+kuhIqMJhh7lmi4Gnba1djDGJokFbuSQSEdi+vfqE0tbaxRiTDJpUQAf48cfg6621izEm0TW5gG7DARhjklWTC+hTplQfhdFauxhjkkGTC+g5OfDkk66VC7gSu90QNcYkg6QdPrcmF14Ia9bA3XfD+++HroYxxphE0uRK6H6XXOKeb7jBjbzYrJmNwGiMSWxNsoQOLnj37g0vvVTRjHH9epuizhiTuJpsCR3g+++tTboxJnk06YDuTfhdjbVJN8YkoiYd0K1NujEmmTTpgB5sijprk26MSVRNOqDn5MBTT0Hz5m7Z2qQbYxJZk23l4peTA/n58MgjbnjdVq1inSNjjKmbJl1C9xsxAvbutfboxpjE1uRL6ACbNrnnzZvds7VHN8YkolpL6CLytIhsFpHlIbbniMgy7/GxiPSNfjYb1r33Vl9n7dGNMYkmnCqXZ4GRNWz/BhiqqlnAPcATUchXowrV7tzaoxtjEkmtAV1VFwAhpoUAVf1YVbd6iwuByCbBiwOh2p1be3RjTCKJ9k3R8cCboTaKyAQRyRORvHiaqHbKlOqtW6w9ujEm0UQtoIvIcFxAvylUGlV9QlV9qurr0qVLtA5db/4x0v2djKw9ujEmEUWllYuIZAFPAaNUtSga+2xsOTnw7bdw882wcCEcdFCsc2SMMZGpdwldRA4FXgIuVNWv65+l2Bkxwj2//35s82GMMXURTrPFWcB/gaNEpEBExovIRBGZ6CW5HegEPCIiS0QkrwHz26D694e2beG992KdE2OMiZxo1QHBG4nP59O8vPiL/aeeCkuWuPFdNmxwLV2mTLH6dGNMfBCRfFX1BdtmPUWraNcONm6sWLZeo8aYRGFjuVQRrLrFeo0aYxKBBfQqvv8++HrrNWqMiXcW0KuwWYyMMYnKAnoVU6ZUTHjhZ71GjTGJwAJ6FTk5cNttFcvWa9QYkygsoAdx882utcuECbBunQVzY0xisIAeRGoqDBkCH3wQ65wYY0z4LKCHMHiwm2O0uDjWOTHGmPBYQA9h8GD3vGhRbPNhjDHhsoAewnHHgYi7IWqTRxtjEoF1/Q+hXTvo1g1eeQX273frbBgAY0w8sxJ6DbZurQjmfjYMgDEmXllAr8HOncHX2zAAxph4ZAG9BoccEny9DQNgjIlHFtBrcN991dfZMADGmHgVzoxFT4vIZhFZHmK7iMh0EVktIstEJDv62YyNCy+ErCw3touIDQNgjIlv4ZTQnwVG1rB9FHCE95gAPFr/bMWPs8+G0lJ3g9SGATDGxLNaA7qqLgB+rCHJGcA/1FkIdBCRg6OVwVgbPBhUYfHiWOfEGGNqFo069K7AtwHLBd66akRkgojkiUheYWFhFA7d8AYMcNUt1mPUGBPvohHQJci6oDNPq+oTqupTVV+XLl2icOiG1749HH20BXRjTPyLRkAvALoHLHcDNoZIm5AGDnQBXYN+TRljTHyIRkCfC1zktXYZBGxT1U1R2G/cGDgQCgvdUAA2posxJl7VOpaLiMwChgGdRaQAuANoDqCqjwFvAKcAq4FdwKUNldlYKSpyzxu93x02posxJh6JxqgewefzaV5eXkyOHakePYJ39+/RwzVlNMaYxiIi+arqC7bNeoqG4dtvg6+3MV2MMfHEAnoYQo3dYmO6GGPiiQX0MEyZAi1aVF5nY7oYY+KNBfQw5OTAAw9ULNuYLsaYeGQBPUy//70bTjcnx8Z0McbEJwvoYRJx7dEXLox1TowxJjgL6BEYPBjWrIHNm2OdE2OMqc4CegQGD3bPVko3xsQjC+gROPZYSE2F//431jkxxpjqLKBHoFUr6N8fXnnFjedi47oYY+JJrWO5mMoOOAA++aRi2cZ1McbECyuhRyg/v/q6Xbtg8uTGz4sxxgSygB6hLVuCr7dxXYwxsWYBPUI2rosxJl5ZQI/QH/8IKSmV19m4LsaYeGABPUI5OXD++RXLNq6LMSZehBXQRWSkiKwUkdUiMinI9kNFZL6IfCYiy0TklOhnNX5cfbV7fuklG9fFGBM/ag3oIpICzABGAb2AsSLSq0qyW4EXVbU/MAZ4JNoZjSfZ2W44XetgZIyJJ+GU0AcAq1V1raruA2YDZ1RJo0A773V7YGP0shh/WrZ0Qd0CujEmnoQT0LsCgZOwFXjrAt0JjPMmkX4D+H2wHYnIBBHJE5G8wsLCOmQ3fgweDHl5sG9frHNijDFOOAFdgqyrOrP0WOBZVe0GnAI8LyLV9q2qT6iqT1V9Xbp0iTy3cWTwYNizB5YujXVOjDHGCSegFwDdA5a7Ub1KZTzwIoCq/hdIAzpHI4Pxyj/y4q9/bWO6GGPiQzgB/RPgCBHpKSItcDc951ZJswEYASAix+ACemLXqdTi/ffdpBdbt4JqxZguFtSNMbFSa0BX1VLgamAesALXmuULEblbREZ7yW4AfisiS4FZwCWqWrVaJqlMnuwCeSAb08UYE0sSq7jr8/k0Ly8vJseOhmbNqgd0cKX2/fsbPz/GmKZBRPJV1Rdsm/UUrSMb08UYE28soNfRlCluwotANqaLMSaWLKDXUU4OPPmk62QENqaLMSb2bMaiesjJgU8/hRkz4KuvIC0t1jkyxjRlVkKvp+HDYe9e+PjjWOfEGNPUWUCvp6FD3fjo77wT65wYY5o6C+j11LYtDBwIb78d65wYY5o6C+hRcNJJbqCu4uJY58QY05RZQI+CESNcZ6Ijj7RxXYwxsWOtXKLgm2/cs39EYP+4LmDNGI0xjcdK6FFwxx3V19m4LsaYxmYBPQo2bIhsvTHGNAQL6FFg47oYY+KBBfQosHFdjDHxwAJ6FPjHdUlPd8uHHmrjuhhjGl9YAV1ERorIShFZLSKTQqQ5T0S+FJEvROSf0c1m/MvJgUceca9ffdWCuTGm8dUa0EUkBZgBjAJ6AWNFpFeVNEcANwPHq2pv4NoGyGvc+9Wv3PO//x3bfBhjmqZwSugDgNWqulZV9wGzgTOqpPktMENVtwKo6uboZjMxHHII9OljAd0YExvhBPSuwLcBywXeukBHAkeKyEcislBERkYrg4mme3c3UJeI9Rg1xjSucHqKSpB1VWfTTAWOAIYB3YAPRCRTVSuNbiIiE4AJAIcmYZu+3NzKoy5aj1FjTGMKp4ReAHQPWO4GbAyS5lVVLVHVb4CVuABfiao+oao+VfV16dKlrnmOW5Mnu7HRA1mPUWNMYwknoH8CHCEiPUWkBTAGmFslzSvAcAAR6YyrglkbzYwmAusxaoyJpVoDuqqWAlcD84AVwIuq+oWI3C0io71k84AiEfkSmA/cqKpFDZXpeGU9Ro0xsSSqVavDG4fP59O8vLyYHLuh5Oa6OvNduyrWpadbJyNjTPSISL6q+oJts56iUZST44K3v0TeqpUFc2NM47GAHmU5Oa51yzXXgCqcdVasc2SMaSosoDeQ006DPXvg3XdjnRNjTFNhAb2BnHACpKXB2LE2LZ0xpnHYFHQNZM4cKClxpXSwTkbGmIZnJfQGMnkylJVVXmedjIwxDckCegOxTkbGmMZmAb2BWCcjY0xjs4DeQKZMqZjByM+mpTPGNCQL6A3E38mouzesWevW1snIGNOwLKA3oJwcV2c+frzrZHT66bHOkTEmmVlAbwSXX+5auLzwQqxzYoxJZhbQG8Hq1dC8uWuHbh2MjDENxQJ6A8vNhSuucJ2MoKKDkQV1Y0y0WUBvYJMnVx5OF6yDkTGmYVhAb2DWwcgY01jCCugiMlJEVorIahGZVEO6c0RERSTo4OtNkXUwMsY0lloDuoikADOAUUAvYKyI9AqSri1wDbAo2plMZME6GInAPffEJj/GmOQVTgl9ALBaVdeq6j5gNnBGkHT3APcDe6KYv4Tn72DUo4cL5G3auDbpF11kLV6MMdEVTkDvCnwbsFzgrSsnIv2B7qr6Wk07EpEJIpInInmFhYURZzZR5eTAunXw/POVR2C0Fi/GmGgKJ6BLkHXlM0uLSDPgIeCG2nakqk+oqk9VfV26dAk/l0li8mTYvbvyOmvxYoyJlnACegHQPWC5G7AxYLktkAm8JyLrgEHAXLsxWp21eDHGNKRwAvonwBEi0lNEWgBjgLn+jaq6TVU7q2qGqmYAC4HRqprXIDlOYNbixRjTkGoN6KpaClwNzANWAC+q6hcicreIjG7oDCaTYC1eUlNtSF1jTHSIqtaeqgH4fD7Ny2t6hfjcXFdnvmGDG9+lpMS1eunRwwV2G17XGFMTEclX1aBV2tZTtJEFtnhp1swFc7AWL8aY+rOAHiOTJ8OeKi32rcWLMaY+LKDHiLV4McZEmwX0GAnVsuXggxs3H8aY5GEBPUaCtXgBaNcO9u9v/PwYYxKfBfQYCRzjBSAlxT1/9RVcemns8mWMSVwW0GMoJ6eipB44xss//gH33x+7fBljEpMF9BgLNqMRwKRJ8L//20rxjH8AABETSURBVPj5McYkLgvoMRaqVYsqnHcejBpV0VbdGGNqYgE9xmobx+Wtt+C66xonL8aYxGYBPcZCtXYJ9Le/wU8/NU5+jDGJywJ6jFVt7RJMWRnce2/j5ckYk5gsoMcB//guoYJ669bwl7/AihWNmi1jTIKxgB5HQlW/tGjhHqNGwcqVjZ8vY0xisIAeR/zVL506VV6/daurdtm6FY4/HhYvjk3+jDHxzQJ6nMnJgTZtqq/fs8etb98ehg+H//u/xs+bMSa+hRXQRWSkiKwUkdUiMinI9utF5EsRWSYi74hIDbf4TG1CtU3fuBH27YMDD4Qzz4SHH27cfBlj4lutAV1EUoAZwCigFzBWRHpVSfYZ4FPVLGAOYB3X66GmtukFBfD999C/P1xzDVx5ZfVx1Y0xTVM4JfQBwGpVXauq+4DZwBmBCVR1vqr6O7AvBLpFN5tNS21t03fvhsJCuPFGeOwxGDgQli2DRYtca5iXXmq8vBpj4kdqGGm6At8GLBcAA2tIPx54M9gGEZkATAA41Ka6D8k/r+jkyW5qumA2bIC+feH11+Hii93rQFddBQ895OYtDWbfPlfaP+yw6OXbGBNb4ZTQJci6oKOLiMg4wAc8EGy7qj6hqj5V9XXp0iX8XDZBtbVNBzcH6datsHQp/PGPMGeOC9I33AAzZsDJJ8N777ngHUgVzj0Xjj4avvmmIc/CGNOYwgnoBUD3gOVuwMaqiUTkJGAyMFpV90Yne6am6pddu2DcOPjFL1y9+9lnQ9euMHWqG4J30SLXIuaAA+Cii2DbNve+Rx+FuXOhpMRV0RhjkkM4Af0T4AgR6SkiLYAxwNzABCLSH3gcF8w3Rz+bTZe/bXpN1q93pfXc3Ip1F17obp6++qp7PWsWDBjgSvE33OA6KV16KTz9tKuPD8dll8Ho0XU/l2jbsKHiS8oYA6hqrQ/gFOBrYA0w2Vt3Ny6AA7wN/AAs8R5za9vnscceqyZ8PXqousqS0I8ePUK/f8EC1QMPdOl+9jPV779XXbFCVUT1tttqP/6HH1Yc5+OPo3VWdbdvnzuPceNinRNjGheQpyHiqmiMBtv2+Xyal5cXk2MnotxcVwoPNhlGoJkzK26qVrVxI9x0E/z2t3DCCW7dWWfB+++70m6wDk3gwvgvfuF+CezZA8OGxb4lzbx5MHKkm4O1sNANjWBMUyAi+arqC7bNeoomiHBGZYTqVS+BDjkEnn++IpiDC/Bbt7obqNdeC48/DqtWVZ5UY84cWLjQjfh41VXwyivw9df1P6f6ePFF97x9u7vxa4zBSuiJKJzSeo8e7oZqqNJ6oLvucnXtX39dMe56z56ufXvPnq7+vW1b+Owz2LLF7fvii13w91N12488MnRJP1pKSlxv2RNPhDffhEsuca164sULL8C//uV+Ldkvh+gqK3N/gwccELpJbiwUFsLy5dCyJXTo4J737nWPgw5yDxHYscMVmDp0qHuT4ZpK6BbQE1RurmvhUhMRF2jDDe6qsHo1/Pvf7rF8uauKKStzVRy/+pVLN3EiPPusK7kfeyysXevazL//vvsjnTkTBg+u/Rw++ghuvRX+9CcYNCis0wbcLE6jRrmWOk8/DXl5Lp8SrIFtI9uwAXr3hp07XQui66+PdY6Sw65d7lr/5S+uOS+4oD5oEJx2GgwdCikpUFpa8di/H5o1c4/UVPflmprqtu3b5/5e0tLco7TUVSfu3u1+9W3bBsXF7rFtm7ueO3e67Xv3urT+gL1mTe3Nf1u1cgUdfwOEG2+s+0TwFtCTVEZG6I5HVaWnuyqbcErsgUpL3R9yhw4V61avdoF8+/aKdQce6IYhePZZF9Suucb9s/XsCUcd5QYVC/T6664t/O7dbtvbb4Mv6J9odZdd5krAmze7Xw+XXuqC+rHH1v5e1YYL/KouuLz3HvTr574Qv/7afTaNSdWNyPnxx67Zat++lc9Z1ZUS16xxgaZVKxf0/Le9y8pcMExNdSXNFi1csPSnKStzD3/g3LevIsA1a+ZKziIVAW/fPpdu715XQt25E4qKXHDbvt2N99+2rcubP3Du2OG2+ZeLitzfyuDBbq7d7dvhu+/gnXfceTS0li1dQE5Pd18ALVtWPA45xP2a7dfPfS7Fxe5c09LcZ7Fxoyv0bN8OP/85HHEEZGe7/426qCmgh9NT1MSpKVPCu1EKLs3FF7vXkQT11NTKwRzg8MNd0F6yxHVqSk11+27d2s1/es01MG1a5fd07w7HHON+erZqBU895QLNk0/COee4Ovxnn3XH2r/f7at9e3fTs3Vr94+UkuKCwyuvuMHJWrZ0AbRZM1dlVFtAnzPH3RAeOhTuvNP9A0bTrFnwxhuuh+7IkdCnj/vl8tRTddufqgsMu3a5gFlS4gKGPzBu2+a+XJcvd6XWFi1cEFm4sKIUC9Crlxt2uVkzt68FC8IvCDSU9HTo0sVd41273LmIuKDZurW77l26uKDXtq1bPvtsGDKk8n5U4auvID+/oiTufwR+AZWWus+vpMQF2ebN3bY9e9wjNdV9dq1auWO1bQsdO7q/x/bt46t6pyZWQk9wubk1DxFQVaTVMHW1c6f7Gbp2rfuHW77cPW/e7Epmw4e7ANiunQs+J5wA335b8z4PPtiVdpcsccMHn3aaW3/CCa5UtGxZ8PeVlcFtt7mqnT593HGKi11gP/xw1xmrUyeXl/R0FzB373ZBQNV9wfifd+2CH390Aci/fedOVwpbutTt/6OP3JfPDTe44D51qquKatnSfQZffumO0aGDC2AlJS6olJW5/JaUuJL98uXuWLVp397tv6TE5fuII2DMGPe5zJsH//xnxU3slBTXH+HXv4asrIovDP8vF5GK0ri/VL1vnzv3srKK7SkpLsilprrnVq3cF8r+/S4fqhUlWH9VR4sWLlC2bevWm7qxKpcmINxmjVW1bu1KJj/+6HqbNmSQr0lRkas28ZesfvrJBd3t293rHTtcIF692gWQN9+sCAoPPuiC5wEHuFJd69ZuH+Ba8Gze7N4/YQJMn+6C3rRp7kvhu+/c9kj+DVq1csE4NdUFuPR096Vw6KHunoD/Zte2ba4aafXqyu/357G42OXLX7JO9X4vN2vmfppnZrpqNf/P/MAA6i9FHnaYO3Y83D8wjcMCehMRWFr3l8QjVde69ljavt2NDb9pkyv979pVUaru2BE6d3Y/1c89N/j7S0oqboTt3l1RR9q8uQuuIhXPrVq57eEqKYEffnBfGrt2ufsJNoyRqQ8L6E1Qbq6r1/b/jI9ESgo891xiBXVjmgrrWNQE5eS4oFzTuOqhlJW58V9EKqoVMjIqOizl5rrlZs0qrzfGxJaV0JNcNKph/Pzvr7qfRKymMSZRWQm9CfOPq67quv136lT3ffmDeNUvBX+TSCupGxNbFtCbkJwc12165kzXbFHEBfhmUfgrqK2apqFY9Y8xFSygN0H+Uvv+/S7A/+Mfdatrr8pfcvffiF2/vnqQ79zZPQIDcF2Dsr+p5vr17tjBxoU3pimxOnQDRLeuvb78x09JcV8OoTpBhRr6oEePyj0ljUkmVodualW1rt0/TG9KintuzI4r4Zb0Q/WOXb++4pdAsF8HdVlXl+ocqw4yjS7UzBeBD2AksBJYDUwKsr0l8IK3fRGQUds+bcaixDJzppsRScQ9X3mlanp67bMoJdNDxD136uQeoJqSEnqdP33go3Xr0O8VCX/fka5LhH0nQh6jtW///9HMmZH/L1KfGYtEJAU3/dyvcBNGfwKMVdUvA9L8DshS1YkiMgY4S1XPr2m/VuWS+OKpmsaYRFSXJr/1rXIZAKxW1bWqug+YDZxRJc0ZwHPe6znACBEbXSLZxVM1jTGJaNcuVyiKlnACelcgcBy8Am9d0DSqWgpsA6q1eBaRCSKSJyJ5heFONW8SQmBw949CGCzId+pU0RbeAr4xbijqaAknoAf7t6v64zqcNKjqE6rqU1VfFxuhKOkFC/JbtrhHYMAXcc8zZ1a0kYfISvrNm9t0byYxHXpo9PYVTkAvALoHLHcDNoZKIyKpQHsgjJGcTVMW2B5+3Tq3HGlJ3/9l8MwzboqywA5T/l8CwX4dRLrOfk2YhpCe7prkRk2ou6X+B25Wo7VAT6AFsBToXSXNVcBj3usxwIu17ddauZhEEtjKJ9wWDf5WDOG+N95aYlgrlyRs5QIgIqcA04AU4GlVnSIid3s7nisiacDzQH9cyXyMqq6taZ/WysUYYyJX7zlFVfUN4I0q624PeL0HCDF9gDHGmMZgPUWNMSZJWEA3xpgkYQHdGGOShAV0Y4xJEjEbPldECoEQ4+WF1BnY0gDZiQU7l/hk5xK/kul86nMuPVQ1aM/MmAX0uhCRvFDNdRKNnUt8snOJX8l0Pg11LlblYowxScICujHGJIlEC+hPxDoDUWTnEp/sXOJXMp1Pg5xLQtWhG2OMCS3RSujGGGNCsIBujDFJIiECuoiMFJGVIrJaRCbFOj+REJHuIjJfRFaIyBci8gdv/QEi8h8RWeU9d4x1XsMlIiki8pmIvOYt9xSRRd65vCAiCTPVhIh0EJE5IvKVd40GJ+q1EZHrvL+x5SIyS0TSEuXaiMjTIrJZRJYHrAt6HcSZ7sWDZSKSHbucVxfiXB7w/saWicjLItIhYNvN3rmsFJFf1+fYcR/QvUmqZwCjgF7AWBHpFdtcRaQUuEFVjwEGAVd5+Z8EvKOqRwDveMuJ4g/AioDlPwMPeeeyFRgfk1zVzV+Bt1T1aKAv7rwS7tqISFfgGsCnqpm4oa7HkDjX5llgZJV1oa7DKOAI7zEBeLSR8hiuZ6l+Lv8BMlU1C/gauBnAiwVjgN7eex7xYl6dxH1AJ7xJquOWqm5S1U+91ztwAaMrlSfWfg44MzY5jIyIdANOBZ7ylgU4ETc5OCTWubQDTgD+DqCq+1S1mAS9NrjhsFt5s4alA5tIkGujqguoPstZqOtwBvAPb76HhUAHETm4cXJau2Dnoqr/VjffMsBC3Mxv4M5ltqruVdVvgNW4mFcniRDQw5mkOiGISAZuEpBFwIGquglc0Ad+FrucRWQa8D/Afm+5E1Ac8MeaSNfnMKAQeMarQnpKRFqTgNdGVb8DpgIbcIF8G5BP4l4bCH0dEj0mXAa86b2O6rkkQkAPawLqeCcibYB/Adeq6vZY56cuROQ0YLOq5geuDpI0Ua5PKpANPKqq/YGfSIDqlWC8+uUzcFNFHgK0xlVNVJUo16YmCfs3JyKTcdWwuf5VQZLV+VwSIaCHM0l1XBOR5rhgnquqL3mrf/D/TPSeN8cqfxE4HhgtIutwVV8n4krsHbyf+ZBY16cAKFDVRd7yHFyAT8RrcxLwjaoWqmoJ8BLwCxL32kDo65CQMUFELgZOA3K0ogNQVM8lEQL6J8AR3t36FrgbCHNjnKeweXXMfwdWqOqDAZvmAhd7ry8GXm3svEVKVW9W1W6qmoG7Du+qag4wHzjHS5YQ5wKgqt8D34rIUd6qEcCXJOC1wVW1DBKRdO9vzn8uCXltPKGuw1zgIq+1yyBgm79qJl6JyEjgJmC0qu4K2DQXGCMiLUWkJ+5G7+I6HyjU7NHx9ABOwd0ZXgNMjnV+Isz7ENxPqGXAEu9xCq7u+R1glfd8QKzzGuF5DQNe814f5v0Rrgb+F2gZ6/xFcB79gDzv+rwCdEzUawPcBXwFLMdN2t4yUa4NMAtX91+CK7WOD3UdcNUUM7x48DmuZU/Mz6GWc1mNqyv3x4DHAtJP9s5lJTCqPse2rv/GGJMkEqHKxRhjTBgsoBtjTJKwgG6MMUnCAroxxiQJC+jGGJMkLKAbY0ySsIBujDFJ4v8BhkzBv7H7j1kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  98.93333371480307\n",
      "Training Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "training_report(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on our set aside testing data\n",
    "def test_model(model, x_test):\n",
    "    #gather the models prediction \n",
    "    \n",
    "    #the model displays its prediction as a percent for every bucket at how confident the model is for \n",
    "    #each bucket. \n",
    "    \n",
    "    #the highest percent in our case the the bucket the model has choosen\n",
    "    preds = model.predict(x_test)\n",
    "    \n",
    "    y_pred = []\n",
    "    \n",
    "    #for ever row in the prediction list\n",
    "    #grab the max value and append that index to the y_pred\n",
    "    for row in preds:\n",
    "        y_pred.append(np.argmax(row))\n",
    "    \n",
    "    #convert the list to a numpy array\n",
    "    return np.asarray(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model against our test data and store the predictions in y_pred\n",
    "y_pred = test_model(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the confusion matrix\n",
    "def test_confusion_matrix(y_pred,y_test):\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the classification report\n",
    "def test_classification_report(y_pred,y_test):\n",
    "    print(skm.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2752    0    0    0    0]\n",
      " [   0 1483    0    0    2]\n",
      " [   0    0 2409    0    0]\n",
      " [   0    4    0 1517    0]\n",
      " [   0   76    0    0  757]]\n"
     ]
    }
   ],
   "source": [
    "test_confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2752\n",
      "           1       0.95      1.00      0.97      1485\n",
      "           2       1.00      1.00      1.00      2409\n",
      "           3       1.00      1.00      1.00      1521\n",
      "           4       1.00      0.91      0.95       833\n",
      "\n",
      "    accuracy                           0.99      9000\n",
      "   macro avg       0.99      0.98      0.98      9000\n",
      "weighted avg       0.99      0.99      0.99      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the classification report on the predictions\n",
    "test_classification_report(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first n rows\n",
    "def drop_first_n_rows(df, n):\n",
    "    return df.iloc[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop frist N rows in data\n",
    "#WHERE N = #OF TRAIN DATA\n",
    "data = drop_first_n_rows(data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the prediction number to bucket number\n",
    "def convert_to_bucket(Y):\n",
    "    #the prediction number is the index of the array 1,2,3,4,5 \n",
    "    #just add 1 to index to correct the bucket number\n",
    "    \n",
    "    #for every index in y\n",
    "    for row in range(0, len(Y)):\n",
    "        #replace the value at the index with value + 1\n",
    "        Y[row] = Y[row] + 1\n",
    "        \n",
    "    #return Y\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pred\n",
    "pred = convert_to_bucket(y_pred)\n",
    "\n",
    "#convert test\n",
    "test = convert_to_bucket(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert our n x 1 numpy array to a pandas df\n",
    "pdpred = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the pred list to the original dataframe\n",
    "\n",
    "data['pred'] = pdpred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the useless data\n",
    "\n",
    "data = data.drop(['subSpecialtyCd', 'fillerOrderStatusCd', 'locationName'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex the columns of the data\n",
    "data = data.reindex(columns=['concat', 'BUCKETNUM', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>BUCKETNUM</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9215</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>*dp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>*dp s incyte diagnostics spokane</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>*ns f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>*gp i incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>*dp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>*dp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>*ns f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8597</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>*gp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>*dp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>*dp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>*gyp s incyte diagnostics bellevue</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>*dp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>*ns t incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>*gip f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>*ns f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8864</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9713</th>\n",
       "      <td>*ns f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>*dp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>*gp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>*gip f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>*gyp f incyte diagnostics bellevue</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>*gip f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>*gp f incyte diagnostics bellevue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>*gp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>*gp f incyte diagnostics spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>*gyp f incyte diagnostics spokane</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  concat  BUCKETNUM  pred\n",
       "9215   *gyp f incyte diagnostics spokane          1     1\n",
       "2667   *gyp f incyte diagnostics spokane          1     1\n",
       "3582    *dp f incyte diagnostics spokane          3     3\n",
       "4159  *gyp f incyte diagnostics bellevue          4     4\n",
       "1417    *dp s incyte diagnostics spokane          5     5\n",
       "6985    *ns f incyte diagnostics spokane          3     3\n",
       "7168   *gp i incyte diagnostics bellevue          2     2\n",
       "931     *dp f incyte diagnostics spokane          3     3\n",
       "5602  *gyp f incyte diagnostics bellevue          4     4\n",
       "3769   *gyp f incyte diagnostics spokane          1     1\n",
       "2895   *dp f incyte diagnostics bellevue          2     2\n",
       "4671   *gip f incyte diagnostics spokane          3     3\n",
       "5282   *gp f incyte diagnostics bellevue          2     2\n",
       "9833   *gip f incyte diagnostics spokane          3     3\n",
       "388    *ns f incyte diagnostics bellevue          2     2\n",
       "9178   *gyp f incyte diagnostics spokane          1     1\n",
       "7011   *gyp f incyte diagnostics spokane          1     1\n",
       "8985   *gyp f incyte diagnostics spokane          1     1\n",
       "5529  *gyp f incyte diagnostics bellevue          4     4\n",
       "2022   *gip f incyte diagnostics spokane          3     3\n",
       "2163  *gyp f incyte diagnostics bellevue          4     4\n",
       "8597   *gip f incyte diagnostics spokane          3     3\n",
       "4947    *gp f incyte diagnostics spokane          3     3\n",
       "96     *gyp f incyte diagnostics spokane          1     1\n",
       "9456   *gip f incyte diagnostics spokane          3     3\n",
       "1462   *dp f incyte diagnostics bellevue          2     2\n",
       "6443    *dp f incyte diagnostics spokane          3     3\n",
       "9438   *gip f incyte diagnostics spokane          3     3\n",
       "3368  *gyp s incyte diagnostics bellevue          5     2\n",
       "8904   *gyp f incyte diagnostics spokane          1     1\n",
       "7441   *gp f incyte diagnostics bellevue          2     2\n",
       "3277  *gyp f incyte diagnostics bellevue          4     4\n",
       "9837  *gyp f incyte diagnostics bellevue          4     4\n",
       "3327  *gyp f incyte diagnostics bellevue          4     4\n",
       "9241    *dp f incyte diagnostics spokane          3     3\n",
       "6063   *ns t incyte diagnostics bellevue          2     2\n",
       "81    *gip f incyte diagnostics bellevue          2     2\n",
       "8716   *gyp f incyte diagnostics spokane          1     1\n",
       "7449   *gyp f incyte diagnostics spokane          1     1\n",
       "1511   *gyp f incyte diagnostics spokane          1     1\n",
       "2618   *gp f incyte diagnostics bellevue          2     2\n",
       "4722    *ns f incyte diagnostics spokane          3     3\n",
       "1603   *gip f incyte diagnostics spokane          3     3\n",
       "768   *gyp f incyte diagnostics bellevue          4     4\n",
       "8864   *gyp f incyte diagnostics spokane          1     1\n",
       "1303   *gyp f incyte diagnostics spokane          1     1\n",
       "9713   *ns f incyte diagnostics bellevue          2     2\n",
       "5240   *gp f incyte diagnostics bellevue          2     2\n",
       "9338    *dp f incyte diagnostics spokane          3     3\n",
       "5397   *gp f incyte diagnostics bellevue          2     2\n",
       "9169   *gyp f incyte diagnostics spokane          1     1\n",
       "8481    *gp f incyte diagnostics spokane          3     3\n",
       "9361   *gip f incyte diagnostics spokane          3     3\n",
       "690   *gyp f incyte diagnostics bellevue          4     4\n",
       "7792   *gyp f incyte diagnostics spokane          1     1\n",
       "6366  *gip f incyte diagnostics bellevue          2     2\n",
       "2876   *gp f incyte diagnostics bellevue          2     2\n",
       "1100    *gp f incyte diagnostics spokane          3     3\n",
       "9011    *gp f incyte diagnostics spokane          3     3\n",
       "4224   *gyp f incyte diagnostics spokane          1     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the data\n",
    "data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
